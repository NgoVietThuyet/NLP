{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a2da94",
   "metadata": {},
   "source": [
    "TỪ TIẾNG VIỆT SANG TIẾNG ANH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0d9c9",
   "metadata": {},
   "source": [
    "## Giai đoạn 1: Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1cdcf",
   "metadata": {},
   "source": [
    "1. Thu thập dữ liệu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b033aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "pip install pyvi # Thư viện dùng riêng tách từ tiếng Việt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "349e50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from pyvi import ViTokenizer  # Thư viện chuyên dùng để tách từ tiếng Việt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9b9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy trên: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cấu hình thiết bị & Hyperparameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Đang chạy trên: {DEVICE}\")\n",
    "\n",
    "# Đổi đường dẫn này đúng với nơi bạn lưu file trên máy\n",
    "DATA_DIR = r\"D:\\Period5\\NLP\\BTL\\Data\" \n",
    "TRAIN_SRC = os.path.join(DATA_DIR, \"train.vi.txt\")\n",
    "TRAIN_TRG = os.path.join(DATA_DIR, \"train.en.txt\")\n",
    "\n",
    "# Thông số huấn luyện\n",
    "BATCH_SIZE = 128        # Số câu xử lý cùng lúc\n",
    "MAX_LEN = 128          # Độ dài câu tối đa\n",
    "FREQ_THRESHOLD = 2     # Bỏ qua các từ xuất hiện dưới 2 lần"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a53e81",
   "metadata": {},
   "source": [
    "2. Tiền xử lý, Xây dựng từ điển\n",
    "\n",
    "Thách thức:\n",
    "Tiếng Anh dùng khoảng trắng để tách từ (*student*), nhưng tiếng Việt có nhiều từ ghép (*sinh viên*, *đất nước*). Nếu chỉ tách bằng khoảng trắng, từ **\"sinh viên\"** sẽ bị tách thành **\"sinh\"** (birth) và **\"viên\"** (pill/member), làm sai lệch nghĩa.\n",
    "\n",
    "**Giải pháp:**  \n",
    "Bắt buộc dùng **tokenizer chuyên dụng** như **PyVi** (dùng thuật toán n-grams) hoặc **VnCoreNLP**.\n",
    "\n",
    "**Ví dụ:**  \n",
    "`\"Học máy rất thú vị\"` → `[\"Học_máy\", \"rất\", \"thú_vị\"]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "572b8e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Đang đọc dữ liệu và xây từ điển...\n",
      "⏳ Đang đếm tần suất từ cho vi...\n",
      "⏳ Đang đếm tần suất từ cho en...\n",
      "✅ Từ vựng Việt (Đã cắt giảm): 15000\n",
      "✅ Từ vựng Anh (Đã cắt giảm): 15000\n"
     ]
    }
   ],
   "source": [
    "# --- SỬA LẠI CELL 2: GIỚI HẠN TỪ VỰNG (QUAN TRỌNG) ---\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
    "        self.stoi = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_vi(text):\n",
    "        return ViTokenizer.tokenize(text).split()\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_en(text):\n",
    "        return text.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"?\", \"\").split()\n",
    "\n",
    "    def build_vocabulary(self, sentence_list, lang=\"vi\", max_size=15000): # <--- THÊM max_size\n",
    "        frequencies = Counter()\n",
    "        tokenizer = self.tokenizer_vi if lang == \"vi\" else self.tokenizer_en\n",
    "\n",
    "        print(f\"⏳ Đang đếm tần suất từ cho {lang}...\")\n",
    "        for sentence in sentence_list:\n",
    "            frequencies.update(tokenizer(sentence))\n",
    "        \n",
    "        # Chỉ lấy top từ phổ biến nhất (trừ đi 4 token đặc biệt)\n",
    "        target_vocab_size = max_size - 4\n",
    "        common_words = frequencies.most_common(target_vocab_size)\n",
    "        \n",
    "        idx = 4\n",
    "        for word, freq in common_words:\n",
    "            self.stoi[word] = idx\n",
    "            self.itos[idx] = word\n",
    "            idx += 1\n",
    "            \n",
    "    def numericalize(self, text, lang=\"vi\"):\n",
    "        tokenizer = self.tokenizer_vi if lang == \"vi\" else self.tokenizer_en\n",
    "        tokenized_text = tokenizer(text)\n",
    "        return [self.stoi.get(token, self.stoi[\"<unk>\"]) for token in tokenized_text]\n",
    "\n",
    "print(\"⏳ Đang đọc dữ liệu và xây từ điển...\")\n",
    "try:\n",
    "    with open(TRAIN_SRC, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f: src_txt = f.readlines()\n",
    "    with open(TRAIN_TRG, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f: trg_txt = f.readlines()\n",
    "\n",
    "    # GIỚI HẠN SỐ LƯỢNG TỪ (15000 là con số an toàn cho máy cá nhân)\n",
    "    src_vocab = Vocabulary()\n",
    "    src_vocab.build_vocabulary(src_txt, \"vi\", max_size=15000)\n",
    "    \n",
    "    trg_vocab = Vocabulary()\n",
    "    trg_vocab.build_vocabulary(trg_txt, \"en\", max_size=15000)\n",
    "\n",
    "    print(f\"✅ Từ vựng Việt (Đã cắt giảm): {len(src_vocab)}\")\n",
    "    print(f\"✅ Từ vựng Anh (Đã cắt giảm): {len(trg_vocab)}\")\n",
    "    \n",
    "    torch.save(src_vocab, \"checkpoints/src_vocab.pth\")\n",
    "    torch.save(trg_vocab, \"checkpoints/trg_vocab.pth\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ LỖI: Không tìm thấy file dữ liệu!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c86180fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test vocalabulary với dữ liệu giả\n",
    "\n",
    "\n",
    "# # Tạo dữ liệu giả (Giả lập file text)\n",
    "# # Lưu ý: \"sinh viên\" xuất hiện 2 lần -> Sẽ được đưa vào từ điển\n",
    "# # \"học máy\" xuất hiện 1 lần -> Sẽ bị loại bỏ (thành <unk>)\n",
    "# sentences = [\n",
    "#     \"tôi là sinh viên đại học\",\n",
    "#     \"sinh viên cần học chăm chỉ\",\n",
    "#     \"học máy rất thú vị\"\n",
    "# ]\n",
    "\n",
    "# # 3. Khởi tạo và xây từ điển\n",
    "# print(\"--- ĐANG TEST VỚI DỮ LIỆU GIẢ ---\")\n",
    "# vocab_test = Vocabulary()\n",
    "# vocab_test.build_vocabulary(sentences, lang=\"vi\")\n",
    "\n",
    "# # 4. Kiểm tra kết quả\n",
    "# print(f\"Tổng số từ trong từ điển: {len(vocab_test)}\")\n",
    "# print(\"Danh sách từ và ID (stoi):\", vocab_test.stoi)\n",
    "\n",
    "# # 5. Test thử biến đổi câu sang số (Numericalize)\n",
    "# cau_test = \"sinh viên học máy\"\n",
    "# input_ids = vocab_test.numericalize(cau_test, lang=\"vi\")\n",
    "\n",
    "# print(f\"\\nCâu gốc: '{cau_test}'\")\n",
    "# print(f\"Tokenized: {Vocabulary.tokenizer_vi(cau_test)}\")\n",
    "# print(f\"Chuyển sang số: {input_ids}\")\n",
    "\n",
    "# # Giải thích kết quả mong đợi:\n",
    "# # - \"sinh_viên\" (có trong stoi) -> Ra số ID cụ thể (ví dụ 4)\n",
    "# # - \"học_máy\" (tần suất < 2, không có trong stoi) -> Ra số 3 (<unk>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eac34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Đang tạo DataLoader...\n",
      "✅ Dữ liệu sẵn sàng! Tổng 3907 batches.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: DATASET & DATALOADER ---\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_lines, trg_lines, src_vocab, trg_vocab):\n",
    "        self.src_lines = src_lines\n",
    "        self.trg_lines = trg_lines\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_lines)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_text = self.src_lines[index].strip()\n",
    "        trg_text = self.trg_lines[index].strip()\n",
    "\n",
    "        # 1. Chuyển chữ sang số\n",
    "        src_token_ids = self.src_vocab.numericalize(src_text, \"vi\")\n",
    "        trg_token_ids = self.trg_vocab.numericalize(trg_text, \"en\")\n",
    "\n",
    "        # 2. QUAN TRỌNG: Cắt bớt nếu câu quá dài (Tránh lỗi IndexError)\n",
    "        # MAX_LEN - 2 vì phải chừa chỗ cho <sos> và <eos>\n",
    "        if len(src_token_ids) > MAX_LEN - 2:\n",
    "            src_token_ids = src_token_ids[:MAX_LEN - 2]\n",
    "        \n",
    "        if len(trg_token_ids) > MAX_LEN - 2:\n",
    "            trg_token_ids = trg_token_ids[:MAX_LEN - 2]\n",
    "\n",
    "        # 3. Thêm <sos> và <eos>\n",
    "        src_encoded = [1] + src_token_ids + [2]\n",
    "        trg_encoded = [1] + trg_token_ids + [2]\n",
    "\n",
    "        return torch.tensor(src_encoded), torch.tensor(trg_encoded)\n",
    "\n",
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        src = [item[0] for item in batch]\n",
    "        trg = [item[1] for item in batch]\n",
    "        src = pad_sequence(src, batch_first=True, padding_value=self.pad_idx)\n",
    "        trg = pad_sequence(trg, batch_first=True, padding_value=self.pad_idx)\n",
    "        return src, trg\n",
    "\n",
    "print(\"⏳ Đang tạo DataLoader...\")\n",
    "train_dataset = TranslationDataset(src_txt, trg_txt, src_vocab, trg_vocab)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=MyCollate(pad_idx=0)\n",
    ")\n",
    "print(f\"✅ Dữ liệu sẵn sàng! Tổng {len(train_loader)} batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f1c4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang lưu bộ từ điển...\n",
      "-> Đã lưu thành công 2 file 'src_vocab.pth' và 'trg_vocab.pth' vào thư mục checkpoints!\n"
     ]
    }
   ],
   "source": [
    "#Lưu bộ từ điển đã tạo ra thành file .pth để dùng lại sau này\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Tạo thư mục checkpoints nếu chưa có để lưu cho gọn\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")\n",
    "\n",
    "print(\"Đang lưu bộ từ điển...\")\n",
    "\n",
    "# 1. Lưu từ điển Tiếng Việt (Source)\n",
    "torch.save(src_vocab, \"checkpoints/src_vocab.pth\")\n",
    "\n",
    "# 2. Lưu từ điển Tiếng Anh (Target)\n",
    "torch.save(trg_vocab, \"checkpoints/trg_vocab.pth\")\n",
    "\n",
    "print(\"-> Đã lưu thành công 2 file 'src_vocab.pth' và 'trg_vocab.pth' vào thư mục checkpoints!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56b31105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã load lại từ điển thành công!\n",
      "Việt: 15000 từ\n",
      "Anh: 15000 từ\n"
     ]
    }
   ],
   "source": [
    "# Load lại\n",
    "src_vocab = torch.load(\"checkpoints/src_vocab.pth\")\n",
    "trg_vocab = torch.load(\"checkpoints/trg_vocab.pth\")\n",
    "\n",
    "print(\"Đã load lại từ điển thành công!\")\n",
    "print(f\"Việt: {len(src_vocab)} từ\")\n",
    "print(f\"Anh: {len(trg_vocab)} từ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6fc0a",
   "metadata": {},
   "source": [
    "## Giai đoạn 2: Xây dựng transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c991713",
   "metadata": {},
   "source": [
    "1. Xây dựng Cơ chế Self-Attention\n",
    "\n",
    "$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdd5cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 2: SELF-ATTENTION ---\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads # Ví dụ: 256 / 8 = 32\n",
    "\n",
    "        assert (self.head_dim * heads == embed_size), \"Embed size phải chia hết cho heads\"\n",
    "\n",
    "        # 3 ma trận trọng số để tạo ra Query, Key, Value\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0] # Batch size\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        # 1. Chia embedding thành các đầu (heads) nhỏ\n",
    "        # Shape: (N, seq_len, heads, head_dim)\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        # 2. Chiếu qua Linear\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        # 3. Tính điểm tương đồng (Dot Product) giữa Query và Key\n",
    "        # \"nqhd,nkhd->nhqk\": Nhân ma trận theo chiều head_dim\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        # 4. Masking (Che đi các từ không được nhìn thấy)\n",
    "        if mask is not None:\n",
    "            # Gán giá trị cực nhỏ (-1e20) vào vị trí padding hoặc tương lai\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        # 5. Softmax: Biến điểm số thành xác suất (0-1)\n",
    "        # Chia căn bậc 2 (embed_size ** 0.5) để ổn định số học\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "\n",
    "        # 6. Nhân xác suất với Value để lấy thông tin\n",
    "        out = torch.einsum(\"nhqk,nvhd->nqhd\", [attention, values])\n",
    "        \n",
    "        # 7. Nối lại thành vector ban đầu\n",
    "        out = out.reshape(N, query_len, self.heads * self.head_dim)\n",
    "        out = self.fc_out(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c74df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        # Attention -> Add & Norm -> FeedForward -> Add & Norm\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81234b0e",
   "metadata": {},
   "source": [
    "2. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30f0f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embed_size, num_layers, heads, device, forward_expansion, dropout, max_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        N, seq_length = x.shape\n",
    "        # Tạo vector vị trí [0, 1, 2...]\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        \n",
    "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9579186",
   "metadata": {},
   "source": [
    "3. Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75158dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = SelfAttention(embed_size, heads=heads)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        # 1. Masked Attention (Tự nhìn bản thân, nhưng che tương lai)\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        \n",
    "        # 2. Cross Attention (Nhìn sang Encoder để lấy thông tin nguồn)\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderBlock(embed_size, heads, forward_expansion, dropout, device) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765b4ba",
   "metadata": {},
   "source": [
    "4. Lắp ráp thành transformer toàn diện\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45868408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 4: FULL TRANSFORMER ---\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, embed_size=256, num_layers=3, forward_expansion=4, heads=8, dropout=0.1, device=\"cpu\", max_length=128):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(src_vocab_size, embed_size, num_layers, heads, device, forward_expansion, dropout, max_length)\n",
    "        self.decoder = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length)\n",
    "        \n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # Mask padding: [Batch, 1, 1, Seq_Len]\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # Mask tam giác (Look-ahead): [Batch, 1, Seq_Len, Seq_Len]\n",
    "        N, trg_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(N, 1, trg_len, trg_len)\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        # Chạy Encoder\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        \n",
    "        # Chạy Decoder\n",
    "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc336a6",
   "metadata": {},
   "source": [
    "## Giai đoạn 3: Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c99f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu huấn luyện 10 epochs...\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    len(src_vocab), len(trg_vocab),\n",
    "    src_vocab.stoi[\"<pad>\"], trg_vocab.stoi[\"<pad>\"],\n",
    "    device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "# NOTE: ignore padding của target (trg), không phải src\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_vocab.stoi[\"<pad>\"])\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "CLIP = 1.0  # gradient clipping\n",
    "print(f\"Bắt đầu huấn luyện {NUM_EPOCHS} epochs...\")\n",
    "\n",
    "best_loss = float('inf')\n",
    "loss_history = []\n",
    "\n",
    "try:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()            # rất quan trọng: bật chế độ train()\n",
    "        epoch_loss = 0.0\n",
    "    \n",
    "        for batch_idx, (src, trg) in enumerate(train_loader):\n",
    "            # chuyển device\n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "\n",
    "            # forward: đưa input cho decoder là trg[:, :-1] (bỏ token cuối EOS)\n",
    "            output = model(src, trg[:, :-1])\n",
    "\n",
    "            # output: (batch, trg_len-1, vocab_size) -> reshape để tính loss\n",
    "            output = output.reshape(-1, output.shape[2])           # (batch*(trg_len-1), vocab_size)\n",
    "            target = trg[:, 1:].reshape(-1)                        # (batch*(trg_len-1),)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # optional: gradient clipping để ổn định\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # optional: in progress từng vài batch để debug\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\" Epoch {epoch+1} | Batch {batch_idx+1}/{len(train_loader)} | batch-loss: {loss.item():.4f}\")\n",
    "\n",
    "        # tính loss trung bình epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # lưu model nếu tốt hơn\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), \"checkpoints/best_transformer.pth\")\n",
    "            print(f\"| -> Đã lưu Kỷ Lục Mới! (Saved Best Model)\")\n",
    "        else:\n",
    "            print(\"|\")\n",
    "\n",
    "except Exception as e:\n",
    "    # nếu có lỗi runtime, in traceback đầy đủ để bạn biết nguyên nhân\n",
    "    print(\"Đã xảy ra lỗi trong quá trình huấn luyện:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcd423",
   "metadata": {},
   "source": [
    "## Giai đoạn 4: Suy luận"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfc98b",
   "metadata": {},
   "source": [
    "## Giai đoạn 5: Đánh giá"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
