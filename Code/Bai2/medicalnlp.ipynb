{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14128026,"sourceType":"datasetVersion","datasetId":9001785},{"sourceId":14128405,"sourceType":"datasetVersion","datasetId":9002085},{"sourceId":14141279,"sourceType":"datasetVersion","datasetId":9011925}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================\n# --- CELL 1: SETUP ---\n# =========================\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport tqdm\nimport warnings\n\n# C√†i ƒë·∫∑t th∆∞ vi·ªán tokenizers n·∫øu ch∆∞a c√≥\ntry:\n    from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\nexcept ImportError:\n    !pip -q install tokenizers\n    from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n\nwarnings.filterwarnings(\"ignore\")\n\n# --- Fix seed ---\ndef set_seed(seed=42):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"‚úÖ Device:\", device)\n\n# --- PATHS (ANH S·ª¨A 2 D√íNG N√ÄY) ---\n# 1) checkpoint best_transformer_en_vi.pt n·∫±m trong Kaggle Input dataset n√†o th√¨ tr·ªè v√†o ƒë√≥\nCKPT_PATH = \"/kaggle/input/modeltrained/best_transformer_en_vi (3).pt\"\n\n# 2) data m·ªõi train.en/train.vi n·∫±m trong Kaggle Input dataset n√†o th√¨ tr·ªè v√†o ƒë√≥\nDATA_DIR = \"/kaggle/input/databaitoanphu\"\n\nSRC_PATH = os.path.join(DATA_DIR, \"train.en.txt\")\nTGT_PATH = os.path.join(DATA_DIR, \"train.vi.txt\")\n\nprint(\"CKPT_PATH:\", CKPT_PATH)\nprint(\"SRC_PATH:\", SRC_PATH)\nprint(\"TGT_PATH:\", TGT_PATH)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:23.968968Z","iopub.execute_input":"2025-12-13T04:14:23.969234Z","iopub.status.idle":"2025-12-13T04:14:27.560301Z","shell.execute_reply.started":"2025-12-13T04:14:23.969211Z","shell.execute_reply":"2025-12-13T04:14:27.559595Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Device: cuda\nCKPT_PATH: /kaggle/input/modeltrained/best_transformer_en_vi (3).pt\nSRC_PATH: /kaggle/input/databaitoanphu/train.en.txt\nTGT_PATH: /kaggle/input/databaitoanphu/train.vi.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==================================\n# --- CELL 2: DATA READING FUNCTION ---\n# ==================================\ndef read_parallel_data(src_path, tgt_path, max_lines=None):\n    pairs = []\n    with open(src_path, \"r\", encoding=\"utf-8\") as fsrc, open(tgt_path, \"r\", encoding=\"utf-8\") as ftgt:\n        for i, (s, t) in enumerate(zip(fsrc, ftgt)):\n            if max_lines and i >= max_lines:\n                break\n            s, t = s.strip(), t.strip()\n            if s and t:\n                pairs.append((s, t))\n    return pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:27.562106Z","iopub.execute_input":"2025-12-13T04:14:27.562711Z","iopub.status.idle":"2025-12-13T04:14:27.568270Z","shell.execute_reply.started":"2025-12-13T04:14:27.562689Z","shell.execute_reply":"2025-12-13T04:14:27.567450Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# =========================\n# --- CELL 3: LOAD DATA ---\n# =========================\nprint(\"\\n--- LOAD DATA M·ªöI (train.en / train.vi) ---\")\n\nall_pairs = read_parallel_data(SRC_PATH, TGT_PATH, max_lines=None)\nprint(\"T·ªïng s·ªë c·∫∑p c√¢u:\", len(all_pairs))\n\n# Shuffle + split 90% train, 10% val\nrandom.shuffle(all_pairs)\nsplit_idx = int(0.9 * len(all_pairs))\ntrain_pairs = all_pairs[:split_idx]\nval_pairs   = all_pairs[split_idx:]\n\nprint(\"Train pairs:\", len(train_pairs))\nprint(\"Val pairs  :\", len(val_pairs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:27.569138Z","iopub.execute_input":"2025-12-13T04:14:27.569418Z","iopub.status.idle":"2025-12-13T04:14:29.670737Z","shell.execute_reply.started":"2025-12-13T04:14:27.569392Z","shell.execute_reply":"2025-12-13T04:14:29.669971Z"}},"outputs":[{"name":"stdout","text":"\n--- LOAD DATA M·ªöI (train.en / train.vi) ---\nT·ªïng s·ªë c·∫∑p c√¢u: 500000\nTrain pairs: 450000\nVal pairs  : 50000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ==============================\n# --- CELL 4: TRAIN TOKENIZERS ---\n# ==============================\nprint(\"\\n--- HU·∫§N LUY·ªÜN TOKENIZER ---\")\n\ndef train_bpe_tokenizer(texts, vocab_size=8000):\n    tokenizer = Tokenizer(models.BPE())\n    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n    tokenizer.decoder = decoders.ByteLevel()\n    \n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=[\"[PAD]\", \"[START]\", \"[END]\", \"[UNK]\"],\n        show_progress=False\n    )\n    tokenizer.train_from_iterator(texts, trainer=trainer)\n    return tokenizer\n\nall_src_text = [p[0] for p in train_pairs + val_pairs]\nall_tgt_text = [p[1] for p in train_pairs + val_pairs]\n\nif not all_src_text:  # Dummy data n·∫øu ch∆∞a load ƒë∆∞·ª£c file\n    all_src_text = [\"Hello world\"]\n    all_tgt_text = [\"Xin ch√†o\"]\n\nen_tokenizer = train_bpe_tokenizer(all_src_text, vocab_size=10000)\nvi_tokenizer = train_bpe_tokenizer(all_tgt_text, vocab_size=10000)\n\n# L·∫•y ID c√°c token ƒë·∫∑c bi·ªát\nPAD_ID = en_tokenizer.token_to_id(\"[PAD]\")\nSTART_ID = vi_tokenizer.token_to_id(\"[START]\")\nEND_ID = vi_tokenizer.token_to_id(\"[END]\")\n\nprint(\"‚úÖ Tokenizer ƒë√£ s·∫µn s√†ng.\")\nprint(\"PAD_ID:\", PAD_ID, \"START_ID:\", START_ID, \"END_ID:\", END_ID)\nprint(\"SRC vocab:\", en_tokenizer.get_vocab_size(), \"TGT vocab:\", vi_tokenizer.get_vocab_size())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:29.671512Z","iopub.execute_input":"2025-12-13T04:14:29.671711Z","iopub.status.idle":"2025-12-13T04:14:57.358463Z","shell.execute_reply.started":"2025-12-13T04:14:29.671696Z","shell.execute_reply":"2025-12-13T04:14:57.357807Z"}},"outputs":[{"name":"stdout","text":"\n--- HU·∫§N LUY·ªÜN TOKENIZER ---\n‚úÖ Tokenizer ƒë√£ s·∫µn s√†ng.\nPAD_ID: 0 START_ID: 1 END_ID: 2\nSRC vocab: 10000 TGT vocab: 10000\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ===========================\n# --- CELL 5: DATASET CLASS ---\n# ===========================\nclass TranslationDataset(Dataset):\n    def __init__(self, pairs, src_tokenizer, tgt_tokenizer, max_len=64):\n        self.pairs = pairs\n        self.src_tok = src_tokenizer\n        self.tgt_tok = tgt_tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        src, tgt = self.pairs[idx]\n\n        src_ids = self.src_tok.encode(src).ids[:self.max_len]\n        tgt_ids = self.tgt_tok.encode(tgt).ids[:self.max_len]\n\n        # Th√™m START/END cho tgt\n        tgt_ids = [START_ID] + tgt_ids + [END_ID]\n\n        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    src_batch = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=PAD_ID)\n    tgt_batch = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=PAD_ID)\n    return src_batch, tgt_batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:57.359362Z","iopub.execute_input":"2025-12-13T04:14:57.359570Z","iopub.status.idle":"2025-12-13T04:14:57.365954Z","shell.execute_reply.started":"2025-12-13T04:14:57.359552Z","shell.execute_reply":"2025-12-13T04:14:57.365189Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ============================\n# --- CELL 6: DATALOADERS ---\n# ============================\nBATCH_SIZE = 64\n\ntrain_ds = TranslationDataset(train_pairs, en_tokenizer, vi_tokenizer, max_len=64)\nval_ds   = TranslationDataset(val_pairs, en_tokenizer, vi_tokenizer, max_len=64)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, drop_last=True)\nval_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\nprint(\"‚úÖ DataLoader ready.\")\nprint(\"Train batches:\", len(train_loader), \"Val batches:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:57.366706Z","iopub.execute_input":"2025-12-13T04:14:57.366970Z","iopub.status.idle":"2025-12-13T04:14:57.388773Z","shell.execute_reply.started":"2025-12-13T04:14:57.366948Z","shell.execute_reply":"2025-12-13T04:14:57.388217Z"}},"outputs":[{"name":"stdout","text":"‚úÖ DataLoader ready.\nTrain batches: 7031 Val batches: 782\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ===================================\n# --- CELL 7: MODEL COMPONENTS ---\n# ===================================\n# --- Rotary Positional Embeddings ---\ndef rotate_half(x):\n    x1, x2 = x.chunk(2, dim=-1)\n    return torch.cat((-x2, x1), dim=-1)\n\ndef apply_rotary_pos_emb(x, cos, sin):\n    return (x * cos) + (rotate_half(x) * sin)\n\nclass RotaryPositionalEncoding(nn.Module):\n    def __init__(self, head_dim, max_seq_len=2048):\n        super().__init__()\n        inv_freq = 1.0 / (10000 ** (torch.arange(0, head_dim, 2).float() / head_dim))\n        t = torch.arange(max_seq_len).float()\n        freqs = torch.outer(t, inv_freq)\n        emb = torch.cat((freqs, freqs), dim=-1)\n        self.register_buffer(\"cos\", emb.cos()[None, None, :, :])\n        self.register_buffer(\"sin\", emb.sin()[None, None, :, :])\n\n    def forward(self, x, seq_len):\n        return self.cos[:, :, :seq_len, :], self.sin[:, :, :seq_len, :]\n\n# --- SwiGLU ---\nclass SwiGLU(nn.Module):\n    def __init__(self, hidden_dim, ffn_dim):\n        super().__init__()\n        self.w1 = nn.Linear(hidden_dim, ffn_dim)\n        self.w2 = nn.Linear(hidden_dim, ffn_dim)\n        self.w3 = nn.Linear(ffn_dim, hidden_dim)\n\n    def forward(self, x):\n        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n\n# --- GQA Attention ---\nclass GQA(nn.Module):\n    def __init__(self, hidden_dim, num_heads, num_kv_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.num_kv_heads = num_kv_heads\n        self.head_dim = hidden_dim // num_heads\n        self.num_groups = num_heads // num_kv_heads\n        \n        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n        self.k_proj = nn.Linear(hidden_dim, num_kv_heads * self.head_dim)\n        self.v_proj = nn.Linear(hidden_dim, num_kv_heads * self.head_dim)\n        self.o_proj = nn.Linear(hidden_dim, hidden_dim)\n        self.dropout = dropout\n\n    def forward(self, x, enc_out=None, mask=None, rope_cos=None, rope_sin=None):\n        batch, seq_len, _ = x.shape\n        kv_input = enc_out if enc_out is not None else x\n\n        q = self.q_proj(x).view(batch, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        k = self.k_proj(kv_input).view(batch, -1, self.num_kv_heads, self.head_dim).transpose(1, 2)\n        v = self.v_proj(kv_input).view(batch, -1, self.num_kv_heads, self.head_dim).transpose(1, 2)\n\n        if rope_cos is not None:\n            q = apply_rotary_pos_emb(q, rope_cos, rope_sin)\n            k = apply_rotary_pos_emb(k, rope_cos, rope_sin)\n\n        k = k.repeat_interleave(self.num_groups, dim=1)\n        v = v.repeat_interleave(self.num_groups, dim=1)\n\n        attn_scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n\n        if mask is not None:\n            attn_scores = attn_scores + mask\n\n        attn = F.softmax(attn_scores, dim=-1)\n        attn = F.dropout(attn, p=self.dropout, training=self.training)\n\n        out = attn @ v\n        out = out.transpose(1, 2).contiguous().view(batch, seq_len, -1)\n        return self.o_proj(out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:57.390930Z","iopub.execute_input":"2025-12-13T04:14:57.391223Z","iopub.status.idle":"2025-12-13T04:14:57.440539Z","shell.execute_reply.started":"2025-12-13T04:14:57.391206Z","shell.execute_reply":"2025-12-13T04:14:57.439826Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ==================================\n# --- CELL 8: TRANSFORMER MODEL ---\n# ==================================\nclass TransformerBlock(nn.Module):\n    def __init__(self, hidden_dim, num_heads, num_kv_heads, dropout=0.1, is_decoder=False):\n        super().__init__()\n        self.norm1 = nn.RMSNorm(hidden_dim)\n        self.attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n        self.is_decoder = is_decoder\n        if is_decoder:\n            self.norm2 = nn.RMSNorm(hidden_dim)\n            self.cross_attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n        self.norm_ffn = nn.RMSNorm(hidden_dim)\n        self.ffn = SwiGLU(hidden_dim, hidden_dim * 4)\n\n    def forward(self, x, enc_out=None, mask=None, cross_mask=None, rope_cos=None, rope_sin=None):\n        x = x + self.attn(self.norm1(x), mask=mask, rope_cos=rope_cos, rope_sin=rope_sin)\n        if self.is_decoder:\n            x = x + self.cross_attn(self.norm2(x), enc_out=enc_out, mask=cross_mask)\n        x = x + self.ffn(self.norm_ffn(x))\n        return x\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab, tgt_vocab, hidden_dim=256, num_layers=4, num_heads=8, num_kv_heads=4):\n        super().__init__()\n        self.src_emb = nn.Embedding(src_vocab, hidden_dim)\n        self.tgt_emb = nn.Embedding(tgt_vocab, hidden_dim)\n        self.rope = RotaryPositionalEncoding(hidden_dim // num_heads)\n        \n        self.encoders = nn.ModuleList([\n            TransformerBlock(hidden_dim, num_heads, num_kv_heads, is_decoder=False)\n            for _ in range(num_layers)\n        ])\n        self.decoders = nn.ModuleList([\n            TransformerBlock(hidden_dim, num_heads, num_kv_heads, is_decoder=True)\n            for _ in range(num_layers)\n        ])\n        self.final_norm = nn.RMSNorm(hidden_dim)\n        self.fc_out = nn.Linear(hidden_dim, tgt_vocab)\n\n    def forward(self, src, tgt, src_mask, tgt_mask):\n        x = self.src_emb(src)\n        rope_cos, rope_sin = self.rope(x, x.shape[1])\n        for layer in self.encoders:\n            x = layer(x, mask=src_mask, rope_cos=rope_cos, rope_sin=rope_sin)\n        enc_out = x\n        \n        x = self.tgt_emb(tgt)\n        rope_cos_tgt, rope_sin_tgt = self.rope(x, x.shape[1])\n        for layer in self.decoders:\n            x = layer(x, enc_out=enc_out, mask=tgt_mask, cross_mask=src_mask, rope_cos=rope_cos_tgt, rope_sin=rope_sin_tgt)\n        return self.fc_out(self.final_norm(x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:57.441177Z","iopub.execute_input":"2025-12-13T04:14:57.441362Z","iopub.status.idle":"2025-12-13T04:14:57.456918Z","shell.execute_reply.started":"2025-12-13T04:14:57.441338Z","shell.execute_reply":"2025-12-13T04:14:57.456262Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ============================\n# --- CELL 9: INIT TRAINING ---\n# ============================\ndef create_masks(src, tgt):\n    src_mask = (src == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n    batch, seq_len = tgt.shape\n    causal = torch.triu(torch.full((seq_len, seq_len), float('-inf'), device=device), diagonal=1)\n    tgt_pad = (tgt == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n    return src_mask, causal + tgt_pad\n\nmodel = Transformer(\n    src_vocab=en_tokenizer.get_vocab_size(),\n    tgt_vocab=vi_tokenizer.get_vocab_size(),\n    hidden_dim=256, num_layers=4, num_heads=8, num_kv_heads=4\n).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_ID, label_smoothing=0.1)\noptimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.0001)\n\nprint(\"Model Initialized.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:14:57.457669Z","iopub.execute_input":"2025-12-13T04:14:57.457915Z","iopub.status.idle":"2025-12-13T04:15:00.490807Z","shell.execute_reply.started":"2025-12-13T04:14:57.457889Z","shell.execute_reply":"2025-12-13T04:15:00.490217Z"}},"outputs":[{"name":"stdout","text":"Model Initialized.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ==========================================\n# --- CELL 10: LOAD BEST CHECKPOINT + RESUME ---\n# ==========================================\nprint(\"\\n--- LOAD best_transformer_en_vi.pt & TRAIN TI·∫æP ---\")\n\nckpt = torch.load(CKPT_PATH, map_location=device)\n\n# ckpt ƒë√∫ng format t·ª´ notebook c≈©:\n# {\"epoch\":..., \"model_state_dict\":..., \"optimizer_state_dict\":..., \"val_loss\":...}\n\nstate_dict = ckpt[\"model_state_dict\"]\n\n# B·ªé 2 buffer RoPE b·ªã l·ªách shape gi·ªØa checkpoint v√† model hi·ªán t·∫°i\nfor k in [\"rope.cos\", \"rope.sin\"]:\n    if k in state_dict:\n        state_dict.pop(k)\n\n# load v·ªõi strict=False ƒë·ªÉ ch·∫•p nh·∫≠n missing ƒë√∫ng 2 key tr√™n\nmodel.load_state_dict(state_dict, strict=False)\n\n# resume optimizer n·∫øu anh mu·ªën train ti·∫øp ƒë√∫ng tr·∫°ng th√°i (khuy·∫øn ngh·ªã)\nif \"optimizer_state_dict\" in ckpt:\n    optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n    # ƒë·∫£m b·∫£o optimizer states n·∫±m ƒë√∫ng device\n    for state in optimizer.state.values():\n        for k, v in state.items():\n            if torch.is_tensor(v):\n                state[k] = v.to(device)\n\nstart_epoch = ckpt.get(\"epoch\", 0)\nbest_prev_val = ckpt.get(\"val_loss\", None)\n\nprint(f\"‚úÖ Loaded checkpoint from: {CKPT_PATH}\")\nprint(f\"   start_epoch = {start_epoch}\")\nprint(f\"   prev_best_val_loss = {best_prev_val}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:15:00.491548Z","iopub.execute_input":"2025-12-13T04:15:00.491946Z","iopub.status.idle":"2025-12-13T04:15:02.578774Z","shell.execute_reply.started":"2025-12-13T04:15:00.491924Z","shell.execute_reply":"2025-12-13T04:15:02.578028Z"}},"outputs":[{"name":"stdout","text":"\n--- LOAD best_transformer_en_vi.pt & TRAIN TI·∫æP ---\n‚úÖ Loaded checkpoint from: /kaggle/input/modeltrained/best_transformer_en_vi (3).pt\n   start_epoch = 7\n   prev_best_val_loss = 3.338132079766721\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# =========================\n# --- CELL 11: EARLY STOP ---\n# =========================\nimport math\nimport torch\n\nclass EarlyStopping:\n    def __init__(self, patience=3, min_delta=1e-4, mode=\"min\"):\n        \"\"\"\n        mode=\"min\": metric c√†ng nh·ªè c√†ng t·ªët (val_loss)\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.mode = mode\n\n        self.best = None\n        self.num_bad_epochs = 0\n\n    def _is_improvement(self, current):\n        if self.best is None:\n            return True\n        if self.mode == \"min\":\n            return current < (self.best - self.min_delta)\n        else:\n            return current > (self.best + self.min_delta)\n\n    def step(self, current):\n        if self._is_improvement(current):\n            self.best = current\n            return False\n        else:\n            self.num_bad_epochs += 1\n            print(f\"S·ªë epoch k√©m ch·∫•t l∆∞·ª£ng {self.num_bad_epochs}\" )\n            return self.num_bad_epochs >= self.patience\n\n\ndef save_checkpoint(path, model, optimizer, epoch, val_loss):\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"val_loss\": val_loss,\n    }, path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:15:02.579565Z","iopub.execute_input":"2025-12-13T04:15:02.579767Z","iopub.status.idle":"2025-12-13T04:15:02.585901Z","shell.execute_reply.started":"2025-12-13T04:15:02.579744Z","shell.execute_reply":"2025-12-13T04:15:02.585314Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ======================================\n# --- CELL 12: CONTINUE TRAINING LOOP ---\n# ======================================\nimport time \nEPOCHS_MORE = 30                 # train ti·∫øp th√™m bao nhi√™u epoch tu·ª≥ anh\nearly = EarlyStopping(patience=3, min_delta=1e-4, mode=\"min\")\n\n# n·∫øu checkpoint c√≥ best val tr∆∞·ªõc ƒë√≥ th√¨ set l√†m m·ªëc\nif best_prev_val is not None:\n    early.best = best_prev_val\n\nbest_path = \"best_transformer_en_vi_resume.pt\"\n\nprint(\"\\n--- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN TI·∫æP ---\")\n\nfor ep in range(EPOCHS_MORE):\n    epoch = start_epoch + ep  # epoch th·ª±c t√≠nh ti·∫øp\n    t0 = time.time() \n    model.train()\n    train_loss = 0\n    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{start_epoch+EPOCHS_MORE}\")\n\n    for src, tgt in pbar:\n        src, tgt = src.to(device), tgt.to(device)\n        tgt_input, tgt_real = tgt[:, :-1], tgt[:, 1:]\n        src_mask, tgt_mask = create_masks(src, tgt_input)\n\n        optimizer.zero_grad()\n        output = model(src, tgt_input, src_mask, tgt_mask)\n\n        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_real.reshape(-1))\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        train_loss += loss.item()\n        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n    avg_train = train_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for src, tgt in val_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            tgt_input, tgt_real = tgt[:, :-1], tgt[:, 1:]\n            src_mask, tgt_mask = create_masks(src, tgt_input)\n            output = model(src, tgt_input, src_mask, tgt_mask)\n            val_loss += criterion(output.reshape(-1, output.shape[-1]), tgt_real.reshape(-1)).item()\n\n    avg_val = val_loss / len(val_loader)\n    epoch_time = time.time() - t0\n    m, s = divmod(epoch_time, 60)\n    h, m = divmod(m, 60)\n    print(f\"Epoch {epoch+1} | Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f} | Time: {int(h):02d}:{int(m):02d}:{s:05.2f}\")\n\n    # save best + early stopping\n    if early.best is None or avg_val < early.best - early.min_delta:\n        save_checkpoint(best_path, model, optimizer, epoch+1, avg_val)\n        print(f\"  ‚Ü≥ Saved BEST to {best_path} (val_loss={avg_val:.4f})\")\n\n    if early.step(avg_val):\n        print(f\"üõë Early stopping at epoch {epoch+1}. Best val_loss = {early.best:.4f}\")\n        break\n\n# (tu·ª≥ ch·ªçn) v·∫´n l∆∞u last state\ntorch.save(model.state_dict(), \"last_transformer_en_vi_resume.pth\")\nprint(\"‚úÖ Done. Saved: best_transformer_en_vi_resume.pt & last_transformer_en_vi_resume.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T04:19:53.287851Z","iopub.execute_input":"2025-12-13T04:19:53.288184Z","iopub.status.idle":"2025-12-13T10:57:00.426909Z","shell.execute_reply.started":"2025-12-13T04:19:53.288164Z","shell.execute_reply":"2025-12-13T10:57:00.426177Z"}},"outputs":[{"name":"stdout","text":"\n--- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN TI·∫æP ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:52<00:00,  9.11it/s, loss=2.7842]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 3.2456 | Val Loss: 2.7712 | Time: 00:13:24.62\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.7712)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:45<00:00,  9.18it/s, loss=2.5473]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 2.6633 | Val Loss: 2.5809 | Time: 00:13:17.36\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.5809)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:39<00:00,  9.26it/s, loss=2.5249]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 2.5061 | Val Loss: 2.4935 | Time: 00:13:10.75\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.4935)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:40<00:00,  9.24it/s, loss=2.3307]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 2.4143 | Val Loss: 2.4400 | Time: 00:13:12.39\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.4400)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:41<00:00,  9.24it/s, loss=2.5297]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 2.3491 | Val Loss: 2.4013 | Time: 00:13:13.24\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.4013)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:40<00:00,  9.25it/s, loss=2.3175]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 2.2985 | Val Loss: 2.3724 | Time: 00:13:12.14\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.3724)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:37<00:00,  9.28it/s, loss=2.2185]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 2.2576 | Val Loss: 2.3510 | Time: 00:13:09.97\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.3510)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:39<00:00,  9.26it/s, loss=2.2005]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 2.2225 | Val Loss: 2.3366 | Time: 00:13:10.75\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.3366)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:41<00:00,  9.24it/s, loss=2.1629]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | Train Loss: 2.1922 | Val Loss: 2.3200 | Time: 00:13:13.74\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.3200)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:51<00:00,  9.12it/s, loss=2.1965]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | Train Loss: 2.1655 | Val Loss: 2.3063 | Time: 00:13:23.57\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.3063)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:51<00:00,  9.11it/s, loss=2.1364]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | Train Loss: 2.1419 | Val Loss: 2.2936 | Time: 00:13:24.29\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2936)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:51<00:00,  9.11it/s, loss=2.1977]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | Train Loss: 2.1205 | Val Loss: 2.2880 | Time: 00:13:24.53\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2880)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:49<00:00,  9.13it/s, loss=2.1918]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | Train Loss: 2.1010 | Val Loss: 2.2798 | Time: 00:13:21.83\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2798)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:40<00:00,  9.25it/s, loss=2.0429]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 | Train Loss: 2.0832 | Val Loss: 2.2759 | Time: 00:13:11.67\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2759)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:36<00:00,  9.30it/s, loss=2.0821]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 | Train Loss: 2.0664 | Val Loss: 2.2651 | Time: 00:13:07.79\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2651)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:39<00:00,  9.26it/s, loss=2.0927]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 | Train Loss: 2.0514 | Val Loss: 2.2620 | Time: 00:13:10.70\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2620)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:38<00:00,  9.27it/s, loss=2.1392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 | Train Loss: 2.0373 | Val Loss: 2.2551 | Time: 00:13:10.41\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2551)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:38<00:00,  9.27it/s, loss=2.1346]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 | Train Loss: 2.0238 | Val Loss: 2.2501 | Time: 00:13:10.56\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2501)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:36<00:00,  9.29it/s, loss=2.2158]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 | Train Loss: 2.0113 | Val Loss: 2.2468 | Time: 00:13:08.05\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2468)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:36<00:00,  9.30it/s, loss=1.9397]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 | Train Loss: 1.9997 | Val Loss: 2.2395 | Time: 00:13:07.92\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2395)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:37<00:00,  9.28it/s, loss=2.0281]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 | Train Loss: 1.9888 | Val Loss: 2.2408 | Time: 00:13:09.67\nS·ªë epoch k√©m ch·∫•t l∆∞·ª£ng 1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:37<00:00,  9.28it/s, loss=1.9171]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 | Train Loss: 1.9783 | Val Loss: 2.2344 | Time: 00:13:09.49\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2344)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:41<00:00,  9.23it/s, loss=1.9716]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 | Train Loss: 1.9685 | Val Loss: 2.2322 | Time: 00:13:13.80\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2322)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:41<00:00,  9.23it/s, loss=1.9761]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 | Train Loss: 1.9340 | Val Loss: 2.2214 | Time: 00:13:13.32\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2214)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:41<00:00,  9.24it/s, loss=1.9008]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 | Train Loss: 1.9260 | Val Loss: 2.2210 | Time: 00:13:13.00\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2210)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:39<00:00,  9.25it/s, loss=1.9553]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 | Train Loss: 1.9186 | Val Loss: 2.2194 | Time: 00:13:11.42\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2194)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [12:38<00:00,  9.26it/s, loss=1.9509]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 | Train Loss: 1.9117 | Val Loss: 2.2168 | Time: 00:13:10.74\n  ‚Ü≥ Saved BEST to best_transformer_en_vi_resume.pt (val_loss=2.2168)\n‚úÖ Done. Saved: best_transformer_en_vi_resume.pt & last_transformer_en_vi_resume.pth\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ==========================================\n# LOAD BEST CHECKPOINT\n# ==========================================\nimport os, torch\n\n# CKPT_PATH = \"best_transformer_en_vi_resume.pt\"  (ƒë√¢y l√† tr·∫°ng th√°i khi train h·∫øt 37 epoch)\nCKPT_PATH = \"/kaggle/input/startstatus/best_transformer_en_vi_resume.pt\" # ƒë√¢y l√† tr·∫°ng th√°i ·ªü epoch: 23 val_loss: 2.261958536589542\nassert os.path.exists(CKPT_PATH), f\"Kh√¥ng th·∫•y file ckpt: {CKPT_PATH}\"\n\nckpt = torch.load(CKPT_PATH, map_location=device)\n\n# ckpt c·ªßa anh th∆∞·ªùng l√† dict c√≥ model_state_dict...\nif isinstance(ckpt, dict):\n    print(\"‚úÖ ckpt keys:\", list(ckpt.keys())[:20])\n    print(\"epoch:\", ckpt.get(\"epoch\"), \"val_loss:\", ckpt.get(\"val_loss\"))\nelse:\n    print(\"‚úÖ ckpt is a raw state_dict (not a dict wrapper)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T13:02:18.222110Z","iopub.execute_input":"2025-12-13T13:02:18.222617Z","iopub.status.idle":"2025-12-13T13:02:20.113426Z","shell.execute_reply.started":"2025-12-13T13:02:18.222596Z","shell.execute_reply":"2025-12-13T13:02:20.112832Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ckpt keys: ['epoch', 'model_state_dict', 'optimizer_state_dict', 'val_loss']\nepoch: 23 val_loss: 2.261958536589542\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# ==========================================\n# LOAD WEIGHTS INTO EXISTING MODEL\n# ==========================================\n# 1) N·∫øu checkpoint l√† wrapper dict\nstate_dict = ckpt[\"model_state_dict\"] if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt else ckpt\n\n# 2) model ph·∫£i t·ªìn t·∫°i t·ª´ tr∆∞·ªõc (∆∞u ti√™n t√°i s·ª≠ d·ª•ng)\nassert \"model\" in globals(), \"Ch∆∞a th·∫•y bi·∫øn model. H√£y ch·∫°y cell t·∫°o model tr∆∞·ªõc (gi·ªëng l√∫c train).\"\n\nmissing, unexpected = model.load_state_dict(state_dict, strict=False)\nprint(\"‚úÖ Loaded state_dict\")\nprint(\"missing keys:\", len(missing))\nprint(\"unexpected keys:\", len(unexpected))\n\nmodel.to(device)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T13:02:30.783366Z","iopub.execute_input":"2025-12-13T13:02:30.783882Z","iopub.status.idle":"2025-12-13T13:02:30.802425Z","shell.execute_reply.started":"2025-12-13T13:02:30.783848Z","shell.execute_reply":"2025-12-13T13:02:30.801876Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded state_dict\nmissing keys: 0\nunexpected keys: 0\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (src_emb): Embedding(10000, 256)\n  (tgt_emb): Embedding(10000, 256)\n  (rope): RotaryPositionalEncoding()\n  (encoders): ModuleList(\n    (0-3): 4 x TransformerBlock(\n      (norm1): RMSNorm((256,), eps=None, elementwise_affine=True)\n      (attn): GQA(\n        (q_proj): Linear(in_features=256, out_features=256, bias=True)\n        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n        (o_proj): Linear(in_features=256, out_features=256, bias=True)\n      )\n      (norm_ffn): RMSNorm((256,), eps=None, elementwise_affine=True)\n      (ffn): SwiGLU(\n        (w1): Linear(in_features=256, out_features=1024, bias=True)\n        (w2): Linear(in_features=256, out_features=1024, bias=True)\n        (w3): Linear(in_features=1024, out_features=256, bias=True)\n      )\n    )\n  )\n  (decoders): ModuleList(\n    (0-3): 4 x TransformerBlock(\n      (norm1): RMSNorm((256,), eps=None, elementwise_affine=True)\n      (attn): GQA(\n        (q_proj): Linear(in_features=256, out_features=256, bias=True)\n        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n        (o_proj): Linear(in_features=256, out_features=256, bias=True)\n      )\n      (norm2): RMSNorm((256,), eps=None, elementwise_affine=True)\n      (cross_attn): GQA(\n        (q_proj): Linear(in_features=256, out_features=256, bias=True)\n        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n        (o_proj): Linear(in_features=256, out_features=256, bias=True)\n      )\n      (norm_ffn): RMSNorm((256,), eps=None, elementwise_affine=True)\n      (ffn): SwiGLU(\n        (w1): Linear(in_features=256, out_features=1024, bias=True)\n        (w2): Linear(in_features=256, out_features=1024, bias=True)\n        (w3): Linear(in_features=1024, out_features=256, bias=True)\n      )\n    )\n  )\n  (final_norm): RMSNorm((256,), eps=None, elementwise_affine=True)\n  (fc_out): Linear(in_features=256, out_features=10000, bias=True)\n)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"# ==========================================\n# LOAD TEST DATA (EN->VI)\n# ==========================================\nTEST_SRC_PATH = \"/kaggle/input/databaitoanphu/public_test.en.txt\"\nTEST_TGT_PATH = \"/kaggle/input/databaitoanphu/public_test.vi.txt\"\n\nassert os.path.exists(TEST_SRC_PATH), f\"Kh√¥ng th·∫•y test src: {TEST_SRC_PATH}\"\nassert os.path.exists(TEST_TGT_PATH), f\"Kh√¥ng th·∫•y test tgt: {TEST_TGT_PATH}\"\n\n# N·∫øu notebook ƒë√£ c√≥ h√†m read_parallel_data(...) th√¨ d√πng lu√¥n\nif \"read_parallel_data\" in globals():\n    test_pairs = read_parallel_data(TEST_SRC_PATH, TEST_TGT_PATH)\nelse:\n    # fallback ƒë∆°n gi·∫£n (kh√¥ng ƒë·ª•ng v√†o logic ch√≠nh)\n    test_pairs = []\n    with open(TEST_SRC_PATH, \"r\", encoding=\"utf-8\") as fs, open(TEST_TGT_PATH, \"r\", encoding=\"utf-8\") as ft:\n        for s, t in zip(fs, ft):\n            s, t = s.strip(), t.strip()\n            if s and t:\n                test_pairs.append((s, t))\n\nprint(\"‚úÖ #test pairs:\", len(test_pairs))\nprint(\"sample:\", test_pairs[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:30:41.652780Z","iopub.execute_input":"2025-12-13T11:30:41.653477Z","iopub.status.idle":"2025-12-13T11:30:41.703015Z","shell.execute_reply.started":"2025-12-13T11:30:41.653448Z","shell.execute_reply":"2025-12-13T11:30:41.702433Z"}},"outputs":[{"name":"stdout","text":"‚úÖ #test pairs: 3000\nsample: ('Knowledge, practices in public health service utilization among health insurance card‚Äôs holders and influencing factors in Vientiane, Lao', 'Th·ª±c tr·∫°ng ki·∫øn th·ª©c v√† th·ª±c h√†nh c·ªßa ng∆∞·ªùi c√≥ th·∫ª b·∫£o hi·ªÉm y t·∫ø trong s·ª≠ d·ª•ng d·ªãch v·ª• kh√°m ch·ªØa b·ªánh ·ªü c√°c c∆° s·ªü y t·∫ø c√¥ng v√† m·ªôt s·ªë y·∫øu t·ªë ·∫£nh h∆∞·ªüng t·∫°i t·ªânh Vi√™ng ChƒÉn, CHDCND L√†o, nƒÉm 2017')\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# =====================================\n# --- FULL: BEAM SEARCH DECODING ---\n# =====================================\nimport torch\nimport torch.nn.functional as F\n\n@torch.no_grad()\ndef beam_search_decode(\n    model,\n    src,                      # (1, src_len)\n    beam_size=5,\n    max_len=80,\n    length_penalty=0.7\n):\n    \"\"\"\n    Beam search decode for 1 sentence.\n\n    Assumes these globals already exist (as in your notebook):\n      - device\n      - PAD_ID   (src pad id)\n      - START_ID (tgt start id)\n      - END_ID   (tgt end id)\n\n    Returns:\n      best_tokens: List[int] (includes START_ID, may include END_ID)\n    \"\"\"\n    model.eval()\n    src = src.to(device)\n\n    # -------------------------\n    # 1) Encoder (run once)\n    # -------------------------\n    src_mask = (src == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9  # (1,1,1,src_len)\n\n    enc = model.src_emb(src)  # (1, src_len, d)\n    rope_cos, rope_sin = model.rope(enc, enc.shape[1])\n\n    for layer in model.encoders:\n        enc = layer(enc, mask=src_mask, rope_cos=rope_cos, rope_sin=rope_sin)\n\n    # -------------------------\n    # 2) Beam init\n    # -------------------------\n    beams = [([START_ID], 0.0)]   # list of (token_ids, log_prob_sum)\n    finished = []                # finished beams that ended with END_ID\n\n    # helper for normalized score\n    def norm_score(tokens, score):\n        L = max(1, len(tokens))\n        return score / (L ** length_penalty)\n\n    # -------------------------\n    # 3) Decode steps\n    # -------------------------\n    for step in range(max_len):\n        new_beams = []\n\n        for tokens, score in beams:\n            # If ended, keep it\n            if tokens[-1] == END_ID:\n                finished.append((tokens, score))\n                new_beams.append((tokens, score))\n                continue\n\n            ys = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)  # (1, t)\n\n            # causal mask (t, t): -inf for future positions\n            tgt_mask = torch.triu(\n                torch.full((ys.size(1), ys.size(1)), float(\"-inf\"), device=device),\n                diagonal=1\n            )\n\n            # ---- Decoder forward ----\n            dec = model.tgt_emb(ys)  # (1, t, d)\n            rope_cos_t, rope_sin_t = model.rope(dec, dec.shape[1])\n\n            x = dec\n            for layer in model.decoders:\n                x = layer(\n                    x,\n                    enc_out=enc,\n                    mask=tgt_mask,\n                    cross_mask=src_mask,\n                    rope_cos=rope_cos_t,\n                    rope_sin=rope_sin_t\n                )\n\n            logits = model.fc_out(model.final_norm(x))[:, -1, :]  # (1, vocab)\n            log_probs = F.log_softmax(logits, dim=-1)             # (1, vocab)\n\n            topk_log_probs, topk_ids = log_probs.topk(beam_size, dim=-1)\n\n            for k in range(beam_size):\n                next_id = topk_ids[0, k].item()\n                next_score = score + topk_log_probs[0, k].item()\n                new_beams.append((tokens + [next_id], next_score))\n\n        # -------------------------\n        # 4) Prune (keep best beams)\n        # -------------------------\n        new_beams = sorted(\n            new_beams,\n            key=lambda x: norm_score(x[0], x[1]),\n            reverse=True\n        )\n\n        beams = new_beams[:beam_size]\n\n        # Early stop: if all current beams are finished\n        if all(toks[-1] == END_ID for toks, _ in beams):\n            break\n\n    # -------------------------\n    # 5) Pick best candidate\n    # -------------------------\n    candidates = finished if finished else beams\n    best_tokens, best_score = max(candidates, key=lambda x: norm_score(x[0], x[1]))\n    return best_tokens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T13:02:47.958128Z","iopub.execute_input":"2025-12-13T13:02:47.958610Z","iopub.status.idle":"2025-12-13T13:02:47.969453Z","shell.execute_reply.started":"2025-12-13T13:02:47.958588Z","shell.execute_reply":"2025-12-13T13:02:47.968690Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# ==========================================\n# QUICK SANITY CHECK: TRANSLATE FEW SAMPLES\n# ==========================================\nNUM_SHOW = 5\n\nfor i in range(NUM_SHOW):\n    src, ref = test_pairs[i]\n\n    # (A) N·∫øu anh ƒë√£ c√≥ h√†m translate_en2vi(text) / translate_sentence(...)\n    if \"translate_en2vi\" in globals():\n        pred = translate_en2vi(src)\n    elif \"translate_sentence\" in globals():\n        # tu·ª≥ signature c·ªßa anh: translate_sentence(model, sentence, ...)\n        pred = translate_sentence(model, src)\n    else:\n        # (B) N·∫øu anh c√≥ beam_search_decode(model, src_ids, ...)\n        assert \"beam_search_decode\" in globals() or \"greedy_decode\" in globals(), \\\n            \"Kh√¥ng th·∫•y h√†m translate/beam/greedy c√≥ s·∫µn. Anh ch·∫°y cell ƒë·ªãnh nghƒ©a decode tr∆∞·ªõc.\"\n\n        # Tokenize theo ƒë√∫ng tokenizer anh ƒë√£ d√πng\n        # ƒë·ªïi t√™n tokenizer cho ƒë√∫ng notebook anh:\n        src_ids = en_tokenizer.encode(src).ids\n        src_ids = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n\n        if \"beam_search_decode\" in globals():\n            out_ids = beam_search_decode(model, src_ids)  # n·∫øu h√†m anh signature kh√°c th√¨ ch·ªânh 1 d√≤ng n√†y\n        else:\n            out_ids = greedy_decode(model, src_ids)\n\n        # decode target\n        pred = vi_tokenizer.decode(out_ids)\n\n    print(\"=\"*80)\n    print(\"SRC:\", src)\n    print(\"REF:\", ref)\n    print(\"PRED:\", pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:33:44.220776Z","iopub.execute_input":"2025-12-13T11:33:44.221510Z","iopub.status.idle":"2025-12-13T11:33:50.246949Z","shell.execute_reply.started":"2025-12-13T11:33:44.221479Z","shell.execute_reply":"2025-12-13T11:33:50.246220Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSRC: Knowledge, practices in public health service utilization among health insurance card‚Äôs holders and influencing factors in Vientiane, Lao\nREF: Th·ª±c tr·∫°ng ki·∫øn th·ª©c v√† th·ª±c h√†nh c·ªßa ng∆∞·ªùi c√≥ th·∫ª b·∫£o hi·ªÉm y t·∫ø trong s·ª≠ d·ª•ng d·ªãch v·ª• kh√°m ch·ªØa b·ªánh ·ªü c√°c c∆° s·ªü y t·∫ø c√¥ng v√† m·ªôt s·ªë y·∫øu t·ªë ·∫£nh h∆∞·ªüng t·∫°i t·ªânh Vi√™ng ChƒÉn, CHDCND L√†o, nƒÉm 2017\nPRED:  Ki·∫øn th·ª©c, th·ª±c h√†nh s·ª≠ d·ª•ng d·ªãch v·ª• y t·∫ø c√¥ng c·ªông c·ªßa ng∆∞·ªùi d√¢n b·∫£o hi·ªÉm y t·∫ø v√† c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng t·∫°i Vii, L√†o Cai\n================================================================================\nSRC: Describe knowledge, practices in public health service utilization among health insurance card's holders and influencing factors in Vientiane, Lao PDR, 2017.\nREF: M√¥ t·∫£ th·ª±c tr·∫°ng ki·∫øn th·ª©c, th·ª±c h√†nh c·ªßa ng∆∞·ªùi c√≥ th·∫ª b·∫£o hi·ªÉm y t·∫ø trong s·ª≠ d·ª•ng d·ªãch v·ª• kh√°m ch·ªØa b·ªánh ·ªü c√°c c∆° s·ªü y t·∫ø c√¥ng v√† m·ªôt s·ªë y·∫øu t·ªë li√™n quan t·∫°i t·ªânh Vi√™ng ChƒÉn, C·ªông ho√† D√¢n ch·ªß Nh√¢n d√¢n L√†o nƒÉm 2017.\nPRED:  M√¥ t·∫£ ki·∫øn th·ª©c, th·ª±c h√†nh v·ªÅ s·ª≠ d·ª•ng d·ªãch v·ª• y t·∫ø c√¥ng c·ªông c·ªßa ng∆∞·ªùi tham gia b·∫£o hi·ªÉm y t·∫ø (BHYT) v√† c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng t·∫°i Viventan, L√†o Cai nƒÉm 2017.\n================================================================================\nSRC: Methodology: A cross sectional study was used among 928 adult health insurance card's holders in Phone Hong and Keo Oudom districts, Vientiane province.\nREF: Ph∆∞∆°ng ph√°p: Thi·∫øt k·∫ø nghi√™n m√¥ t·∫£ c·∫Øt ngang ƒë∆∞·ª£c th·ª±c hi·ªán tr√™n 928 ng∆∞·ªùi tr∆∞·ªüng th√†nh c√≥ th·∫ª b·∫£o hi·ªÉm y t·∫ø t·∫°i 2 huy·ªán Phone Hong v√† Keo Oudom, t·ªânh Vi√™ng ChƒÉn.\nPRED:  ƒê·ªëi t∆∞·ª£ng v√† ph∆∞∆°ng ph√°p nghi√™n c·ª©u: Nghi√™n c·ª©u c·∫Øt ngang m√¥ t·∫£ ƒë∆∞·ª£c th·ª±c hi·ªán tr√™n 928 nh√¢n vi√™n b·∫£o hi·ªÉm y t·∫ø t·∫°i c√°c qu·∫≠n, huy·ªán Phil Hong v√† K·ªÉ t·ª´ th√°ng 9/2011 ƒë·∫øn th√°ng 9/2012.\n================================================================================\nSRC: Results: Percentage of card's holders who knew the finance-free utilization of the first registered public health services was 44.5% and being provided health insurance information was 34.8%.\nREF: K·∫øt qu·∫£: T·ª∑ l·ªá ng∆∞·ªùi bi·∫øt ƒë∆∞·ª£c kh√°m ch·ªØa b·ªánh (KCB) mi·ªÖn ph√≠ t·∫°i n∆°i ƒëƒÉng k√Ω ban ƒë·∫ßu chi·∫øm 44,5%, ƒë∆∞·ª£c cung c·∫•p th√¥ng tin v·ªÅ b·∫£o hi·ªÉm y t·∫ø (BHYT) chi·∫øm 34,8%.\nPRED:  K·∫øt qu·∫£: T·ª∑ l·ªá c√°n b·ªô c·ªßa tr·∫°m y t·∫ø bi·∫øt s·ª≠ d·ª•ng d·ªãch v·ª• y t·∫ø c√¥ng c·ªông kh√¥ng h·ª£p l√Ω l√† 44,5% v√† ƒë∆∞·ª£c cung c·∫•p th√¥ng tin v·ªÅ BHYT l√† 34,8%.\n================================================================================\nSRC: Percentage of card's holders who went to the first registered public health services was 61.8%.\nREF: T·ª∑ l·ªá ng∆∞·ªùi c√≥ th·∫ª BHYT th·ª±c h√†nh kh√°m ch·ªØa b·ªánh ƒë√∫ng n∆°i ƒëƒÉng k√Ω KCB ban ƒë·∫ßu chi·∫øm 61,8%.\nPRED:  T·ª∑ l·ªá c√°n b·ªô c·ªßa tr·∫°m y t·∫ø c√¥ng l·∫≠p ƒëƒÉng k√Ω ban ƒë·∫ßu l√† 61,8%.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"sentence_en = \"Group 1: non-obese mice.\"\nsentence_vi = \"Nh√≥m 1: Chu·ªôt kh√¥ng b√©o ph√¨.\"\n\nprint(\"SRC:\", sentence_en)\nprint(\"TRG:\", sentence_vi)\n\n# 1) Encode EN -> ids tensor\nsrc_ids = en_tokenizer.encode(sentence_en).ids\nsrc = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)  # (1, src_len)\n\n# 2) Beam search -> ids\nout_ids = beam_search_decode(model, src, beam_size=5, max_len=80)\n\n# 3) B·ªè START/END tr∆∞·ªõc khi decode text\nif len(out_ids) > 0 and out_ids[0] == START_ID:\n    out_ids = out_ids[1:]\nif END_ID in out_ids:\n    out_ids = out_ids[:out_ids.index(END_ID)]\n\npred_vi = vi_tokenizer.decode(out_ids)\nprint(\"PRED:\", pred_vi)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T13:04:30.182963Z","iopub.execute_input":"2025-12-13T13:04:30.183560Z","iopub.status.idle":"2025-12-13T13:04:30.472659Z","shell.execute_reply.started":"2025-12-13T13:04:30.183539Z","shell.execute_reply":"2025-12-13T13:04:30.472115Z"}},"outputs":[{"name":"stdout","text":"SRC: Group 1: non-obese mice.\nTRG: Nh√≥m 1: Chu·ªôt kh√¥ng b√©o ph√¨.\nPRED:  Nh√≥m 1: chu·ªôt kh√¥ng thu·∫ßn ch·ªßng.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"!pip install torchtext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:34:59.603697Z","iopub.execute_input":"2025-12-13T11:34:59.603987Z","iopub.status.idle":"2025-12-13T11:36:10.312890Z","shell.execute_reply.started":"2025-12-13T11:34:59.603965Z","shell.execute_reply":"2025-12-13T11:36:10.312167Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting torchtext\n  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.5)\nRequirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.6.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.10.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchtext) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchtext) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchtext) (2024.2.0)\nDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchtext-0.18.0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!pip -q install sacrebleu tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:50:48.345733Z","iopub.execute_input":"2025-12-13T11:50:48.346555Z","iopub.status.idle":"2025-12-13T11:50:51.570836Z","shell.execute_reply.started":"2025-12-13T11:50:48.346525Z","shell.execute_reply":"2025-12-13T11:50:51.569883Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# ==========================================\n# --- BLEU (SACREBLEU) + PROGRESS BAR ---\n# ==========================================\n\n\nimport sacrebleu\nfrom tqdm.auto import tqdm\nimport torch\n\nMAX_EVAL = len(test_pairs)   # ho·∫∑c 2000 ƒë·ªÉ test nhanh\n\npred_texts = []\nref_texts  = []\n\nfor i in tqdm(range(MAX_EVAL), desc=\"Computing BLEU\", unit=\"sent\"):\n    src, ref = test_pairs[i]\n\n    # d√πng h√†m d·ªãch c√≥ s·∫µn c·ªßa anh (∆∞u ti√™n)\n    if \"translate_en2vi\" in globals():\n        pred = translate_en2vi(src)\n    elif \"translate_sentence\" in globals():\n        pred = translate_sentence(model, src)\n    else:\n        # fallback n·∫øu anh ch·ªâ c√≥ beam_search_decode/greedy_decode\n        src_ids = en_tokenizer.encode(src).ids\n        src_ids = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n        out_ids = beam_search_decode(model, src_ids) if \"beam_search_decode\" in globals() else greedy_decode(model, src_ids)\n\n        # b·ªè START/END n·∫øu c·∫ßn (tu·ª≥ model anh)\n        if isinstance(out_ids, torch.Tensor):\n            out_ids = out_ids.squeeze(0).tolist() if out_ids.ndim > 1 else out_ids.tolist()\n\n        if len(out_ids) > 0 and out_ids[0] == START_ID:\n            out_ids = out_ids[1:]\n        if END_ID in out_ids:\n            out_ids = out_ids[:out_ids.index(END_ID)]\n\n        pred = vi_tokenizer.decode(out_ids)\n\n    pred_texts.append(pred.strip())\n    ref_texts.append(ref.strip())\n\nbleu = sacrebleu.corpus_bleu(pred_texts, [ref_texts])\nprint(\"BLEU =\", bleu.score)\nprint(\"detail:\", bleu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T11:50:54.777736Z","iopub.execute_input":"2025-12-13T11:50:54.778487Z","iopub.status.idle":"2025-12-13T12:44:22.920034Z","shell.execute_reply.started":"2025-12-13T11:50:54.778456Z","shell.execute_reply":"2025-12-13T12:44:22.919391Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Computing BLEU:   0%|          | 0/3000 [00:00<?, ?sent/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bf860686794d3b94265b611900f9dd"}},"metadata":{}},{"name":"stdout","text":"BLEU = 46.57571741460038\ndetail: BLEU = 46.58 75.8/58.4/46.4/37.7 (BP = 0.883 ratio = 0.890 hyp_len = 89734 ref_len = 100870)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"T√≠nh Bleu khi train ·ªü epoch: 23 val_loss: 2.261958536589542 ","metadata":{}},{"cell_type":"code","source":"# ==========================================\n# --- BLEU (SACREBLEU) + PROGRESS BAR ---\n# ==========================================\n\n\nimport sacrebleu\nfrom tqdm.auto import tqdm\nimport torch\n\nMAX_EVAL = len(test_pairs)   # ho·∫∑c 2000 ƒë·ªÉ test nhanh\n\npred_texts = []\nref_texts  = []\n\nfor i in tqdm(range(MAX_EVAL), desc=\"Computing BLEU\", unit=\"sent\"):\n    src, ref = test_pairs[i]\n\n    # d√πng h√†m d·ªãch c√≥ s·∫µn c·ªßa anh (∆∞u ti√™n)\n    if \"translate_en2vi\" in globals():\n        pred = translate_en2vi(src)\n    elif \"translate_sentence\" in globals():\n        pred = translate_sentence(model, src)\n    else:\n        # fallback n·∫øu anh ch·ªâ c√≥ beam_search_decode/greedy_decode\n        src_ids = en_tokenizer.encode(src).ids\n        src_ids = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n        out_ids = beam_search_decode(model, src_ids) if \"beam_search_decode\" in globals() else greedy_decode(model, src_ids)\n\n        # b·ªè START/END n·∫øu c·∫ßn (tu·ª≥ model anh)\n        if isinstance(out_ids, torch.Tensor):\n            out_ids = out_ids.squeeze(0).tolist() if out_ids.ndim > 1 else out_ids.tolist()\n\n        if len(out_ids) > 0 and out_ids[0] == START_ID:\n            out_ids = out_ids[1:]\n        if END_ID in out_ids:\n            out_ids = out_ids[:out_ids.index(END_ID)]\n\n        pred = vi_tokenizer.decode(out_ids)\n\n    pred_texts.append(pred.strip())\n    ref_texts.append(ref.strip())\n\nbleu = sacrebleu.corpus_bleu(pred_texts, [ref_texts])\nprint(\"BLEU =\", bleu.score)\nprint(\"detail:\", bleu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T13:09:50.877395Z","iopub.execute_input":"2025-12-13T13:09:50.877702Z","iopub.status.idle":"2025-12-13T14:03:34.716461Z","shell.execute_reply.started":"2025-12-13T13:09:50.877681Z","shell.execute_reply":"2025-12-13T14:03:34.715551Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Computing BLEU:   0%|          | 0/3000 [00:00<?, ?sent/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acdc2dd123544e6a968ef76737a1a37f"}},"metadata":{}},{"name":"stdout","text":"BLEU = 44.982471593436834\ndetail: BLEU = 44.98 74.8/56.8/44.3/35.4 (BP = 0.886 ratio = 0.892 hyp_len = 89958 ref_len = 100870)\n","output_type":"stream"}],"execution_count":48}]}