{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14127011,"sourceType":"datasetVersion","datasetId":9001002},{"sourceId":14128026,"sourceType":"datasetVersion","datasetId":9001785}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================\n# --- CELL 1: SETUP ---\n# =========================\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport tqdm\nimport warnings\n\n# C√†i ƒë·∫∑t th∆∞ vi·ªán tokenizers n·∫øu ch∆∞a c√≥\ntry:\n    from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\nexcept ImportError:\n    !pip -q install tokenizers\n    from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n\nwarnings.filterwarnings(\"ignore\")\n\n# --- Fix seed ---\ndef set_seed(seed=42):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"‚úÖ Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:53:39.254038Z","iopub.execute_input":"2025-12-12T14:53:39.254269Z","iopub.status.idle":"2025-12-12T14:53:43.127279Z","shell.execute_reply.started":"2025-12-12T14:53:39.254238Z","shell.execute_reply":"2025-12-12T14:53:43.126505Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n\n# --- CELL 2: DATA READING FUNCTION ---\ndef read_parallel_files(src_filename, tgt_filename):\n    \"\"\"ƒê·ªçc c·∫∑p file song ng·ªØ, tr·∫£ v·ªÅ list c√°c tuple (c√¢u_ngu·ªìn, c√¢u_ƒë√≠ch)\"\"\"\n    # Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n (h·ªó tr·ª£ c·∫£ th∆∞ m·ª•c hi·ªán t·∫°i v√† th∆∞ m·ª•c input c·ªßa Kaggle)\n    possible_paths = [\"./\", \"/kaggle/input/\", \"/kaggle/working/\"]\n    \n    src_path, tgt_path = None, None\n    for p in possible_paths:\n        if os.path.exists(os.path.join(p, src_filename)):\n            src_path = os.path.join(p, src_filename)\n        if os.path.exists(os.path.join(p, tgt_filename)):\n            tgt_path = os.path.join(p, tgt_filename)\n            \n    if not src_path or not tgt_path:\n        print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file {src_filename} ho·∫∑c {tgt_filename}. B·ªè qua.\")\n        return []\n\n    print(f\"üìñ ƒêang ƒë·ªçc: {src_path} v√† {tgt_path}\")\n    with open(src_path, 'r', encoding='utf-8') as f_src, \\\n         open(tgt_path, 'r', encoding='utf-8') as f_tgt:\n        src_lines = [line.strip() for line in f_src.read().splitlines()]\n        tgt_lines = [line.strip() for line in f_tgt.read().splitlines()]\n    \n    # L·ªçc b·ªè c√°c c·∫∑p c√¢u r·ªóng ho·∫∑c l·ªách d√≤ng\n    pairs = []\n    min_len = min(len(src_lines), len(tgt_lines))\n    for i in range(min_len):\n        if src_lines[i] and tgt_lines[i]:\n            pairs.append((src_lines[i], tgt_lines[i]))\n            \n    return pairs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- CELL 3: LOAD DATA ---\nprint(\"\\n--- ƒêANG T·∫¢I D·ªÆ LI·ªÜU ---\")\n# ƒê·∫£m b·∫£o t√™n file kh·ªõp v·ªõi file b·∫°n upload\ntrain_pairs = read_parallel_files(\"/kaggle/input/maindata/train.en\", \"/kaggle/input/maindata/train.vi\")\ntest_pairs = read_parallel_files(\"/kaggle/input/maindata/tst2013.en\", \"/kaggle/input/maindata/tst2013.vi\")\nval_pairs = read_parallel_files(\"/kaggle/input/maindata/tst2012.en\", \"/kaggle/input/maindata/tst2012.vi\")\nprint(f\"‚úÖ Train size: {len(train_pairs)}\")\nprint(f\"‚úÖ Test size: {len(test_pairs)}\")\n\nif len(train_pairs) > 0:\n    print(f\"üîé V√≠ d·ª• m·∫´u: {train_pairs[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:01.068436Z","iopub.execute_input":"2025-12-12T13:05:01.068607Z","iopub.status.idle":"2025-12-12T13:05:01.373942Z","shell.execute_reply.started":"2025-12-12T13:05:01.068592Z","shell.execute_reply":"2025-12-12T13:05:01.373165Z"}},"outputs":[{"name":"stdout","text":"\n--- ƒêANG T·∫¢I D·ªÆ LI·ªÜU ---\nüìñ ƒêang ƒë·ªçc: /kaggle/input/maindata/train.en v√† /kaggle/input/maindata/train.vi\nüìñ ƒêang ƒë·ªçc: /kaggle/input/maindata/tst2013.en v√† /kaggle/input/maindata/tst2013.vi\nüìñ ƒêang ƒë·ªçc: /kaggle/input/maindata/tst2012.en v√† /kaggle/input/maindata/tst2012.vi\n‚úÖ Train size: 133166\n‚úÖ Test size: 1268\nüîé V√≠ d·ª• m·∫´u: ('Rachel Pike : The science behind a climate headline', 'Khoa h·ªçc ƒë·∫±ng sau m·ªôt ti√™u ƒë·ªÅ v·ªÅ kh√≠ h·∫≠u')\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# --- CELL 4: TRAIN TOKENIZERS ---\nprint(\"\\n--- HU·∫§N LUY·ªÜN TOKENIZER ---\")\n\ndef train_bpe_tokenizer(texts, vocab_size=8000):\n    tokenizer = Tokenizer(models.BPE())\n    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n    tokenizer.decoder = decoders.ByteLevel()\n    \n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=[\"[PAD]\", \"[START]\", \"[END]\", \"[UNK]\"],\n        show_progress=False\n    )\n    tokenizer.train_from_iterator(texts, trainer=trainer)\n    return tokenizer\n\n# G·ªôp text ƒë·ªÉ train tokenizer\nall_src_text = [p[0] for p in train_pairs + val_pairs]\nall_tgt_text = [p[1] for p in train_pairs + val_pairs]\n\nif not all_src_text: # Dummy data n·∫øu ch∆∞a load ƒë∆∞·ª£c file\n    all_src_text = [\"Hello world\"]\n    all_tgt_text = [\"Xin ch√†o\"]\n\nen_tokenizer = train_bpe_tokenizer(all_src_text, vocab_size=10000)\nvi_tokenizer = train_bpe_tokenizer(all_tgt_text, vocab_size=10000)\n\n# L·∫•y ID c√°c token ƒë·∫∑c bi·ªát\nPAD_ID = en_tokenizer.token_to_id(\"[PAD]\")\nSTART_ID = vi_tokenizer.token_to_id(\"[START]\")\nEND_ID = vi_tokenizer.token_to_id(\"[END]\")\n\nprint(\"‚úÖ Tokenizer ƒë√£ s·∫µn s√†ng.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:01.376006Z","iopub.execute_input":"2025-12-12T13:05:01.376547Z","iopub.status.idle":"2025-12-12T13:05:07.687120Z","shell.execute_reply.started":"2025-12-12T13:05:01.376529Z","shell.execute_reply":"2025-12-12T13:05:07.686632Z"}},"outputs":[{"name":"stdout","text":"\n--- HU·∫§N LUY·ªÜN TOKENIZER ---\n‚úÖ Tokenizer ƒë√£ s·∫µn s√†ng.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# --- CELL 5: DATASET CLASS ---\nclass EnViDataset(Dataset):\n    def __init__(self, pairs):\n        self.pairs = pairs\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        return self.pairs[idx]\n\ndef collate_fn(batch):\n    en_batch, vi_batch = zip(*batch)\n    \n    # Encode ti·∫øng Anh (Source)\n    en_enc = en_tokenizer.encode_batch(list(en_batch))\n    en_ids = [e.ids for e in en_enc]\n    \n    # Encode ti·∫øng Vi·ªát (Target) - Th√™m START v√† END th·ªß c√¥ng\n    vi_ids = []\n    for text in vi_batch:\n        ids = vi_tokenizer.encode(text).ids\n        vi_ids.append([START_ID] + ids + [END_ID])\n    \n    # Padding\n    max_len_en = max([len(x) for x in en_ids])\n    max_len_vi = max([len(x) for x in vi_ids])\n    \n    padded_en = [x + [PAD_ID] * (max_len_en - len(x)) for x in en_ids]\n    padded_vi = [x + [PAD_ID] * (max_len_vi - len(x)) for x in vi_ids]\n    \n    return torch.tensor(padded_en), torch.tensor(padded_vi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:07.687602Z","iopub.execute_input":"2025-12-12T13:05:07.687859Z","iopub.status.idle":"2025-12-12T13:05:07.694014Z","shell.execute_reply.started":"2025-12-12T13:05:07.687842Z","shell.execute_reply":"2025-12-12T13:05:07.693164Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# --- CELL 6: DATALOADERS ---\nBATCH_SIZE = 32\n\ntrain_loader = DataLoader(EnViDataset(train_pairs), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(EnViDataset(val_pairs), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\nprint(f\"DataLoaders created. Batch size: {BATCH_SIZE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:07:59.304980Z","iopub.execute_input":"2025-12-12T13:07:59.305609Z","iopub.status.idle":"2025-12-12T13:07:59.310388Z","shell.execute_reply.started":"2025-12-12T13:07:59.305582Z","shell.execute_reply":"2025-12-12T13:07:59.309600Z"}},"outputs":[{"name":"stdout","text":"DataLoaders created. Batch size: 32\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# --- CELL 7: MODEL COMPONENTS ---\n# --- Rotary Positional Embeddings ---\ndef rotate_half(x):\n    x1, x2 = x.chunk(2, dim=-1)\n    return torch.cat((-x2, x1), dim=-1)\n\ndef apply_rotary_pos_emb(x, cos, sin):\n    return (x * cos) + (rotate_half(x) * sin)\n\nclass RotaryPositionalEncoding(nn.Module):\n    def __init__(self, head_dim, max_seq_len=2048):\n        super().__init__()\n        inv_freq = 1.0 / (10000 ** (torch.arange(0, head_dim, 2).float() / head_dim))\n        t = torch.arange(max_seq_len).float()\n        freqs = torch.outer(t, inv_freq)\n        emb = torch.cat((freqs, freqs), dim=-1)\n        self.register_buffer(\"cos\", emb.cos()[None, :, None, :])\n        self.register_buffer(\"sin\", emb.sin()[None, :, None, :])\n\n    def forward(self, x, seq_len):\n        return self.cos[:, :seq_len, :, :], self.sin[:, :seq_len, :, :]\n\n# --- Feed Forward (SwiGLU) ---\nclass SwiGLU(nn.Module):\n    def __init__(self, hidden_dim, intermediate_dim):\n        super().__init__()\n        self.w1 = nn.Linear(hidden_dim, intermediate_dim)\n        self.w2 = nn.Linear(hidden_dim, intermediate_dim)\n        self.w3 = nn.Linear(intermediate_dim, hidden_dim)\n\n    def forward(self, x):\n        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n\n# --- GQA Attention ---\nclass GQA(nn.Module):\n    def __init__(self, hidden_dim, num_heads, num_kv_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.num_kv_heads = num_kv_heads\n        self.head_dim = hidden_dim // num_heads\n        self.num_groups = num_heads // num_kv_heads\n        \n        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n        self.k_proj = nn.Linear(hidden_dim, num_kv_heads * self.head_dim)\n        self.v_proj = nn.Linear(hidden_dim, num_kv_heads * self.head_dim)\n        self.o_proj = nn.Linear(hidden_dim, hidden_dim)\n        self.dropout = dropout\n\n    def forward(self, x, enc_out=None, mask=None, rope_cos=None, rope_sin=None):\n        batch, seq_len, _ = x.shape\n        kv_input = enc_out if enc_out is not None else x\n        kv_seq_len = kv_input.shape[1]\n\n        q = self.q_proj(x).view(batch, seq_len, self.num_heads, self.head_dim)\n        k = self.k_proj(kv_input).view(batch, kv_seq_len, self.num_kv_heads, self.head_dim)\n        v = self.v_proj(kv_input).view(batch, kv_seq_len, self.num_kv_heads, self.head_dim)\n\n        if rope_cos is not None and enc_out is None:\n            q = apply_rotary_pos_emb(q, rope_cos, rope_sin)\n            k = apply_rotary_pos_emb(k, rope_cos, rope_sin)\n\n        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n\n        if self.num_groups > 1:\n            k = k[:, :, None, :, :].expand(batch, self.num_kv_heads, self.num_groups, kv_seq_len, self.head_dim).reshape(batch, self.num_heads, kv_seq_len, self.head_dim)\n            v = v[:, :, None, :, :].expand(batch, self.num_kv_heads, self.num_groups, kv_seq_len, self.head_dim).reshape(batch, self.num_heads, kv_seq_len, self.head_dim)\n\n        out = F.scaled_dot_product_attention(q, k, v, attn_mask=mask, dropout_p=self.dropout if self.training else 0.0)\n        return self.o_proj(out.transpose(1, 2).reshape(batch, seq_len, -1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:07.735463Z","iopub.execute_input":"2025-12-12T13:05:07.735752Z","iopub.status.idle":"2025-12-12T13:05:07.756094Z","shell.execute_reply.started":"2025-12-12T13:05:07.735735Z","shell.execute_reply":"2025-12-12T13:05:07.755495Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# --- CELL 8: TRANSFORMER MODEL ---\nclass TransformerBlock(nn.Module):\n    def __init__(self, hidden_dim, num_heads, num_kv_heads, dropout=0.1, is_decoder=False):\n        super().__init__()\n        self.norm1 = nn.RMSNorm(hidden_dim)\n        self.attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n        self.is_decoder = is_decoder\n        if is_decoder:\n            self.norm2 = nn.RMSNorm(hidden_dim)\n            self.cross_attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n        self.norm_ffn = nn.RMSNorm(hidden_dim)\n        self.ffn = SwiGLU(hidden_dim, hidden_dim * 4)\n\n    def forward(self, x, enc_out=None, mask=None, cross_mask=None, rope_cos=None, rope_sin=None):\n        x = x + self.attn(self.norm1(x), mask=mask, rope_cos=rope_cos, rope_sin=rope_sin)\n        if self.is_decoder:\n            x = x + self.cross_attn(self.norm2(x), enc_out=enc_out, mask=cross_mask)\n        x = x + self.ffn(self.norm_ffn(x))\n        return x\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab, tgt_vocab, hidden_dim=256, num_layers=4, num_heads=8, num_kv_heads=4):\n        super().__init__()\n        self.src_emb = nn.Embedding(src_vocab, hidden_dim)\n        self.tgt_emb = nn.Embedding(tgt_vocab, hidden_dim)\n        self.rope = RotaryPositionalEncoding(hidden_dim // num_heads)\n        self.encoders = nn.ModuleList([TransformerBlock(hidden_dim, num_heads, num_kv_heads) for _ in range(num_layers)])\n        self.decoders = nn.ModuleList([TransformerBlock(hidden_dim, num_heads, num_kv_heads, is_decoder=True) for _ in range(num_layers)])\n        self.final_norm = nn.RMSNorm(hidden_dim)\n        self.fc_out = nn.Linear(hidden_dim, tgt_vocab)\n\n    def forward(self, src, tgt, src_mask, tgt_mask):\n        x = self.src_emb(src)\n        rope_cos, rope_sin = self.rope(x, x.shape[1])\n        for layer in self.encoders:\n            x = layer(x, mask=src_mask, rope_cos=rope_cos, rope_sin=rope_sin)\n        enc_out = x\n        \n        x = self.tgt_emb(tgt)\n        rope_cos_tgt, rope_sin_tgt = self.rope(x, x.shape[1])\n        for layer in self.decoders:\n            x = layer(x, enc_out=enc_out, mask=tgt_mask, cross_mask=src_mask, rope_cos=rope_cos_tgt, rope_sin=rope_sin_tgt)\n        return self.fc_out(self.final_norm(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:07.756808Z","iopub.execute_input":"2025-12-12T13:05:07.757002Z","iopub.status.idle":"2025-12-12T13:05:07.774416Z","shell.execute_reply.started":"2025-12-12T13:05:07.756988Z","shell.execute_reply":"2025-12-12T13:05:07.773831Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# --- CELL 9: INIT TRAINING ---\ndef create_masks(src, tgt):\n    src_mask = (src == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n    batch, seq_len = tgt.shape\n    causal = torch.triu(torch.full((seq_len, seq_len), float('-inf'), device=device), diagonal=1)\n    tgt_pad = (tgt == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n    return src_mask, causal + tgt_pad\n\nmodel = Transformer(\n    src_vocab=en_tokenizer.get_vocab_size(),\n    tgt_vocab=vi_tokenizer.get_vocab_size(),\n    hidden_dim=256, num_layers=4, num_heads=8, num_kv_heads=4\n).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_ID, label_smoothing=0.1)\noptimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.0001)\n\nprint(\"Model Initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:07.775065Z","iopub.execute_input":"2025-12-12T13:05:07.775218Z","iopub.status.idle":"2025-12-12T13:05:10.610167Z","shell.execute_reply.started":"2025-12-12T13:05:07.775206Z","shell.execute_reply":"2025-12-12T13:05:10.609391Z"}},"outputs":[{"name":"stdout","text":"Model Initialized.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import math\nimport torch\n\nclass EarlyStopping:\n    def __init__(self, patience=3, min_delta=1e-4, mode=\"min\"):\n        \"\"\"\n        mode=\"min\": metric c√†ng nh·ªè c√†ng t·ªët (val_loss)\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.mode = mode\n\n        self.best = None\n        self.num_bad_epochs = 0\n\n    def _is_improvement(self, current):\n        if self.best is None:\n            return True\n        if self.mode == \"min\":\n            return current < (self.best - self.min_delta)\n        else:\n            return current > (self.best + self.min_delta)\n\n    def step(self, current):\n        \"\"\"\n        return True n·∫øu n√™n STOP\n        \"\"\"\n        if self._is_improvement(current):\n            self.best = current\n            self.num_bad_epochs = 0\n            return False\n        else:\n            self.num_bad_epochs += 1\n            return self.num_bad_epochs >= self.patience\n\n\ndef save_checkpoint(path, model, optimizer, epoch, val_loss):\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"val_loss\": val_loss,\n    }, path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:10.612559Z","iopub.execute_input":"2025-12-12T13:05:10.612901Z","iopub.status.idle":"2025-12-12T13:05:10.618685Z","shell.execute_reply.started":"2025-12-12T13:05:10.612884Z","shell.execute_reply":"2025-12-12T13:05:10.617976Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# import gc, torch\n# gc.collect()\n# torch.cuda.empty_cache()\n# torch.cuda.ipc_collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:11:00.598771Z","iopub.execute_input":"2025-12-12T13:11:00.599240Z","iopub.status.idle":"2025-12-12T13:11:00.737782Z","shell.execute_reply.started":"2025-12-12T13:11:00.599215Z","shell.execute_reply":"2025-12-12T13:11:00.736965Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# EPOCHS = 50\n# early = EarlyStopping(patience=3, min_delta=1e-4, mode=\"min\")\n# best_path = \"best_transformer_en_vi.pt\"\n\n# print(\"\\n--- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN ---\")\n\n# for epoch in range(EPOCHS):\n#     model.train()\n#     train_loss = 0\n#     pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n\n#     for src, tgt in pbar:\n#         src, tgt = src.to(device), tgt.to(device)\n#         tgt_input, tgt_real = tgt[:, :-1], tgt[:, 1:]\n#         src_mask, tgt_mask = create_masks(src, tgt_input)\n\n#         optimizer.zero_grad()\n#         output = model(src, tgt_input, src_mask, tgt_mask)\n#         loss = criterion(output.reshape(-1, output.shape[-1]), tgt_real.reshape(-1))\n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#         optimizer.step()\n\n#         train_loss += loss.item()\n#         pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n#     # Validation\n#     model.eval()\n#     val_loss = 0\n#     with torch.no_grad():\n#         for src, tgt in val_loader:\n#             src, tgt = src.to(device), tgt.to(device)\n#             tgt_input, tgt_real = tgt[:, :-1], tgt[:, 1:]\n#             src_mask, tgt_mask = create_masks(src, tgt_input)\n#             output = model(src, tgt_input, src_mask, tgt_mask)\n#             val_loss += criterion(output.reshape(-1, output.shape[-1]), tgt_real.reshape(-1)).item()\n\n#     avg_train = train_loss / len(train_loader)\n#     avg_val = val_loss / len(val_loader)\n#     print(f\"Epoch {epoch+1} | Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f}\")\n\n#     # save best + early stopping\n#     if early.best is None or avg_val < early.best - early.min_delta:\n#         save_checkpoint(best_path, model, optimizer, epoch+1, avg_val)\n#         print(f\"  ‚Ü≥ Saved BEST to {best_path} (val_loss={avg_val:.4f})\")\n\n#     if early.step(avg_val):\n#         print(f\"üõë Early stopping at epoch {epoch+1}. Best val_loss = {early.best:.4f}\")\n#         break\n\n# # (tu·ª≥ ch·ªçn) v·∫´n l∆∞u last state\n# torch.save(model.state_dict(), \"last_transformer_en_vi.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:11:03.029064Z","iopub.execute_input":"2025-12-12T13:11:03.029544Z","iopub.status.idle":"2025-12-12T14:01:01.789078Z","shell.execute_reply.started":"2025-12-12T13:11:03.029519Z","shell.execute_reply":"2025-12-12T14:01:01.788339Z"}},"outputs":[{"name":"stdout","text":"\n--- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:58<00:00, 13.95it/s, loss=3.8881]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 4.1989 | Val Loss: 3.7663\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.7663)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [05:00<00:00, 13.87it/s, loss=3.4853]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 3.4529 | Val Loss: 3.5373\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.5373)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:59<00:00, 13.92it/s, loss=3.0734]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 3.1974 | Val Loss: 3.4424\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.4424)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:58<00:00, 13.96it/s, loss=2.9062]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 3.0443 | Val Loss: 3.3789\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.3789)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:58<00:00, 13.96it/s, loss=3.2277]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 2.9291 | Val Loss: 3.3524\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.3524)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:59<00:00, 13.92it/s, loss=2.9170]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 2.8357 | Val Loss: 3.3452\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.3452)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:57<00:00, 13.98it/s, loss=3.0811]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 2.7559 | Val Loss: 3.3381\n  ‚Ü≥ Saved BEST to best_transformer_en_vi.pt (val_loss=3.3381)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:57<00:00, 13.97it/s, loss=2.8564]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 2.6860 | Val Loss: 3.3418\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:59<00:00, 13.91it/s, loss=2.7402]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 2.6237 | Val Loss: 3.3579\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [04:59<00:00, 13.91it/s, loss=2.5059]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 2.5656 | Val Loss: 3.3702\nüõë Early stopping at epoch 10. Best val_loss = 3.3381\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\n@torch.no_grad()\ndef beam_search_decode(\n    model,\n    src_ids: torch.Tensor,          # shape: (1, src_len)\n    src_mask: torch.Tensor,         # shape: (1, 1, 1, src_len) ho·∫∑c t∆∞∆°ng th√≠ch model\n    beam_size: int = 5,\n    max_len: int = 100,\n    len_penalty: float = 0.6,       # >0 gi√∫p tr√°nh ∆∞u ti√™n c√¢u qu√° ng·∫Øn\n    temperature: float = 1.0,\n):\n    \"\"\"\n    Tr·∫£ v·ªÅ: best_hyp_ids (List[int]) g·ªìm [START, ..., END] (c√≥ th·ªÉ kh√¥ng c√≥ END n·∫øu max_len).\n    Ghi ch√∫: code n√†y ph√π h·ª£p v·ªõi model.forward(src, tgt, src_mask, tgt_mask) nh∆∞ notebook c·ªßa anh.\n    \"\"\"\n    device = src_ids.device\n    model.eval()\n\n    # m·ªói beam: (token_ids, sum_logprob)\n    beams = [([START_ID], 0.0)]\n    finished = []\n\n    for _ in range(max_len):\n        new_beams = []\n\n        for tok_ids, score in beams:\n            # n·∫øu ƒë√£ k·∫øt th√∫c th√¨ ƒë∆∞a v√†o finished\n            if tok_ids[-1] == END_ID:\n                finished.append((tok_ids, score))\n                continue\n\n            tgt = torch.tensor([tok_ids], device=device)  # (1, tlen)\n            tlen = tgt.size(1)\n\n            # causal mask gi·ªëng CELL 11\n            tgt_mask = torch.triu(\n                torch.full((tlen, tlen), float('-inf'), device=device),\n                diagonal=1\n            )\n\n            out = model(src_ids, tgt, src_mask, tgt_mask)  # (1, tlen, vocab)\n            logits = out[0, -1, :] / max(temperature, 1e-8)  # (vocab,)\n\n            log_probs = F.log_softmax(logits, dim=-1)       # (vocab,)\n            topk_log_probs, topk_ids = torch.topk(log_probs, k=beam_size)\n\n            for lp, wid in zip(topk_log_probs.tolist(), topk_ids.tolist()):\n                new_tok_ids = tok_ids + [wid]\n                new_score = score + lp\n                new_beams.append((new_tok_ids, new_score))\n\n        if not new_beams:\n            break\n\n        # length normalization\n        def normed(s, length):\n            # length t√≠nh theo s·ªë token sinh ra (kh√¥ng t√≠nh START)\n            denom = ((5 + length) / 6) ** len_penalty\n            return s / denom\n\n        # gi·ªØ top beam_size\n        new_beams.sort(key=lambda x: normed(x[1], max(1, len(x[0]) - 1)), reverse=True)\n        beams = new_beams[:beam_size]\n\n        # n·∫øu t·∫•t c·∫£ beam ƒë·ªÅu END th√¨ d·ª´ng\n        if all(b[0][-1] == END_ID for b in beams):\n            finished.extend(beams)\n            break\n\n    if finished:\n        finished.sort(key=lambda x: x[1] / (((5 + max(1, len(x[0]) - 1)) / 6) ** len_penalty), reverse=True)\n        return finished[0][0]\n    return beams[0][0]\n\n\ndef translate_beam(sentence: str, beam_size=8, max_len=100, len_penalty=0.6):\n    model.eval()\n    with torch.no_grad():\n        src = torch.tensor([en_tokenizer.encode(sentence).ids]).to(device)\n        src_mask = (src == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n\n        best_ids = beam_search_decode(\n            model=model,\n            src_ids=src,\n            src_mask=src_mask,\n            beam_size=beam_size,\n            max_len=max_len,\n            len_penalty=len_penalty,\n        )\n\n        # b·ªè START, v√† (n·∫øu c√≥) c·∫Øt t·∫°i END\n        if END_ID in best_ids:\n            best_ids = best_ids[1:best_ids.index(END_ID)]\n        else:\n            best_ids = best_ids[1:]\n\n        return vi_tokenizer.decode(best_ids)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:01:14.480567Z","iopub.execute_input":"2025-12-12T14:01:14.480871Z","iopub.status.idle":"2025-12-12T14:01:14.492889Z","shell.execute_reply.started":"2025-12-12T14:01:14.480850Z","shell.execute_reply":"2025-12-12T14:01:14.492147Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"\nfor i in range(5):\n    if len(test_pairs) > 0:\n        idx = random.randint(0, len(test_pairs)-1)\n        en_txt, vi_txt = test_pairs[idx]\n        print(f\"üîπ Input:  {en_txt}\\nüî∏ Target: {vi_txt}\\nüöÄ Model:  {translate_beam(en_txt)}\\n{'-'*50}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:01:23.706200Z","iopub.execute_input":"2025-12-12T14:01:23.707091Z","iopub.status.idle":"2025-12-12T14:01:52.805139Z","shell.execute_reply.started":"2025-12-12T14:01:23.707064Z","shell.execute_reply":"2025-12-12T14:01:52.804388Z"}},"outputs":[{"name":"stdout","text":"üîπ Input:  And he said that he needed those guns because of the trauma he &apos;d experienced as a young boy .\nüî∏ Target: V√† anh ta n√≥i r·∫±ng anh ta c·∫ßn nh·ªØng c√¢y s√∫ng n√†y b·ªüi v√¨ nh·ªØng t·ªïn th∆∞∆°ng m√† anh ƒë√£ tr·∫£i qua trong qu√° kh·ª© khi l√† m·ªôt ƒë·ª©a tr·∫ª .\nüöÄ Model:   V√† √¥ng n√≥i r·∫±ng √¥ng c·∫ßn nh·ªØng s√∫ng ƒë√≥ v√¨ nh·ªØng ch·∫•n th∆∞∆°ng m√† √¥ng ƒë√£ tr·∫£i qua khi c√≤n l√† m·ªôt c·∫≠u b√© .\n--------------------------------------------------\nüîπ Input:  Am I South Korean or North Korean ?\nüî∏ Target: T√¥i l√† ng∆∞·ªùi Nam Tri·ªÅu Ti√™n hay B·∫Øc Tri·ªÅu Ti√™n ?\nüöÄ Model:   T√¥i l√† ng∆∞·ªùi Nam H√†n hay B·∫Øc H√†n hay B·∫Øc H√†n ?\n--------------------------------------------------\nüîπ Input:  And so just as the womb entirely envelopes the embryo , which grows within it , the divine matrix of compassion nourishes the entire existence .\nüî∏ Target: V√† b·ªüi v√¨ t·ª≠ cung bao b·ªçc ho√†n to√†n ph√¥i thai ƒëang ph√°t tri·ªÉn trong l√≤ng n√≥ , ma tr·∫≠n thi√™ng li√™ng c·ªßa t√¨nh th∆∞∆°ng nu√¥i d∆∞·ª°ng to√†n b·ªô s·ª± s·ªëng ƒë√≥ .\nüöÄ Model:   V√† c≈©ng nh∆∞ khi m√† c∆° th·ªÉ ƒë√£ ph√°t tri·ªÉn th√†nh ph√¥i thai , n√≥ ph√°t tri·ªÉn b√™n trong n√≥ , ma tr·∫≠n ph√¢n bi·ªát c·ªßa l√≤ng th∆∞∆°ng √°i .\n--------------------------------------------------\nüîπ Input:  It &apos;s really become sacred to us .\nüî∏ Target: N√≥ tr·ªü n√™n th·∫≠t thi√™ng li√™ng v·ªõi ch√∫ng t√¥i .\nüöÄ Model:   N√≥ th·ª±c s·ª± tr·ªü th√†nh th·ªù ∆° v·ªõi ch√∫ng ta .\n--------------------------------------------------\nüîπ Input:  This is a visualization of six months of my life .\nüî∏ Target: ƒê√¢y l√† nh·ªØng h√¨nh ·∫£nh tr·ª±c quan v·ªÅ cu·ªôc s·ªëng trong s√°u th√°ng ƒë√£ ƒë∆∞·ª£c ghi l·∫°i c·ªßa t√¥i .\nüöÄ Model:   ƒê√¢y l√† h√¨nh ·∫£nh ho√° c·ªßa 6 th√°ng .\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Test th·ªß c√¥ng 1 c√¢u ri√™ng\ncustom_sentence = \"I really like this model.\"\nprint(f\"\\nüöÄ Custom Test Input: {custom_sentence}\")\nprint(f\"‚úÖ Model Translation: {translate_beam(custom_sentence)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:47.330431Z","iopub.status.idle":"2025-12-12T13:05:47.330719Z","shell.execute_reply.started":"2025-12-12T13:05:47.330550Z","shell.execute_reply":"2025-12-12T13:05:47.330562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:01:54.643811Z","iopub.execute_input":"2025-12-12T14:01:54.644768Z","iopub.status.idle":"2025-12-12T14:01:59.030922Z","shell.execute_reply.started":"2025-12-12T14:01:54.644733Z","shell.execute_reply":"2025-12-12T14:01:59.030125Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.11.3)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import sacrebleu\nimport random\nfrom tqdm import tqdm # Thanh hi·ªÉn th·ªã ti·∫øn ƒë·ªô\n\ndef calculate_bleu(data_pairs, num_samples=100):\n    print(f\"--- üìä ƒêANG T√çNH ƒêI·ªÇM BLEU TR√äN {num_samples} M·∫™U ---\")\n    \n    # Ch·ªçn ng·∫´u nhi√™n m·∫´u ƒë·ªÉ test (ho·∫∑c l·∫•y h·∫øt n·∫øu num_samples=None)\n    if num_samples is not None and num_samples < len(data_pairs):\n        samples = random.sample(data_pairs, num_samples)\n    else:\n        samples = data_pairs\n\n    preds = [] # C√°c c√¢u m√°y d·ªãch\n    refs = []  # C√°c c√¢u ƒë√°p √°n chu·∫©n\n\n    # B·∫Øt ƒë·∫ßu d·ªãch\n    for en_txt, vi_txt in tqdm(samples):\n        # D·ªãch c√¢u ti·∫øng Anh\n        pred_sent = translate_beam(en_txt)\n        \n        preds.append(pred_sent)\n        refs.append(vi_txt) # Sacrebleu nh·∫≠n list c√°c string cho refs\n\n    # T√≠nh ƒëi·ªÉm BLEU\n    # refs c·∫ßn ƒë∆∞·ª£c b·ªçc trong list v√¨ 1 c√¢u input c√≥ th·ªÉ c√≥ nhi·ªÅu c√¢u target (·ªü ƒë√¢y ta c√≥ 1)\n    bleu = sacrebleu.corpus_bleu(preds, [refs])\n    \n    return bleu.score\n\n# --- CH·∫†Y T√çNH ƒêI·ªÇM ---\n# B·∫°n c√≥ th·ªÉ tƒÉng s·ªë l∆∞·ª£ng m·∫´u l√™n len(test_pairs) ƒë·ªÉ ch√≠nh x√°c h∆°n (s·∫Ω ch·∫°y l√¢u h∆°n)\nscore = calculate_bleu(test_pairs, num_samples=100)\n\nprint(f\"\\nüåü ƒêI·ªÇM BLEU C·ª¶A MODEL: {score:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:02:31.156886Z","iopub.execute_input":"2025-12-12T14:02:31.157433Z","iopub.status.idle":"2025-12-12T14:12:25.532860Z","shell.execute_reply.started":"2025-12-12T14:02:31.157409Z","shell.execute_reply":"2025-12-12T14:12:25.531945Z"}},"outputs":[{"name":"stdout","text":"--- üìä ƒêANG T√çNH ƒêI·ªÇM BLEU TR√äN 100 M·∫™U ---\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [09:54<00:00,  5.94s/it]","output_type":"stream"},{"name":"stdout","text":"\nüåü ƒêI·ªÇM BLEU C·ª¶A MODEL: 28.21\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"B√†i to√°n ph·ª•\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"CKPT_PATH = \"/kaggle/input/YOUR_CKPT_DATASET/best_transformer_en_vi.pt\"\n\n# 2) data m·ªõi train.en/train.vi n·∫±m trong Kaggle Input dataset n√†o th√¨ tr·ªè v√†o ƒë√≥\nDATA_DIR = \"/kaggle/input/YOUR_NEW_TRAIN_DATASET\"\n\nSRC_PATH = os.path.join(DATA_DIR, \"train.en\")\nTGT_PATH = os.path.join(DATA_DIR, \"train.vi\")\n\nprint(\"CKPT_PATH:\", CKPT_PATH)\nprint(\"SRC_PATH:\", SRC_PATH)\nprint(\"TGT_PATH:\", TGT_PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# --- CELL 3: LOAD DATA ---\n# =========================\nprint(\"\\n--- LOAD DATA M·ªöI (train.en / train.vi) ---\")\n\nall_pairs = read_parallel_data(SRC_PATH, TGT_PATH, max_lines=None)\nprint(\"T·ªïng s·ªë c·∫∑p c√¢u:\", len(all_pairs))\n\n# Shuffle + split 90% train, 10% val\nrandom.shuffle(all_pairs)\nsplit_idx = int(0.9 * len(all_pairs))\ntrain_pairs = all_pairs[:split_idx]\nval_pairs   = all_pairs[split_idx:]\n\nprint(\"Train pairs:\", len(train_pairs))\nprint(\"Val pairs  :\", len(val_pairs))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==========================================\n# --- CELL 10: LOAD BEST CHECKPOINT + RESUME ---\n# ==========================================\nprint(\"\\n--- LOAD best_transformer_en_vi.pt & TRAIN TI·∫æP ---\")\n\nckpt = torch.load(CKPT_PATH, map_location=device)\n\n# ckpt ƒë√∫ng format t·ª´ notebook c≈©:\n# {\"epoch\":..., \"model_state_dict\":..., \"optimizer_state_dict\":..., \"val_loss\":...}\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\n\n# resume optimizer n·∫øu anh mu·ªën train ti·∫øp ƒë√∫ng tr·∫°ng th√°i (khuy·∫øn ngh·ªã)\nif \"optimizer_state_dict\" in ckpt:\n    optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n    # ƒë·∫£m b·∫£o optimizer states n·∫±m ƒë√∫ng device\n    for state in optimizer.state.values():\n        for k, v in state.items():\n            if torch.is_tensor(v):\n                state[k] = v.to(device)\n\nstart_epoch = ckpt.get(\"epoch\", 0)\nbest_prev_val = ckpt.get(\"val_loss\", None)\n\nprint(f\"‚úÖ Loaded checkpoint from: {CKPT_PATH}\")\nprint(f\"   start_epoch = {start_epoch}\")\nprint(f\"   prev_best_val_loss = {best_prev_val}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- CELL 1: SETUP ---\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport tqdm\nimport warnings\n\n# C√†i ƒë·∫∑t th∆∞ vi·ªán tokenizers n·∫øu ch∆∞a c√≥\ntry:\n    import tokenizers\nexcept ImportError:\n    os.system('pip install tokenizers')\n    import tokenizers\n\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n\n# C·∫•u h√¨nh thi·∫øt b·ªã v√† Random Seed\nwarnings.filterwarnings(\"ignore\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"üîπ ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: {device}\")\n\nSEED = 42\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}